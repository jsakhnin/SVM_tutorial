{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial attempts to explain the concept of Support Vector Machines (SVMs) using a combination of theory and application. The first section provides a theoretical background and a mathematical overview of SVMs. The second section demonstrates the use of SVM through a simple linear example as well as a more complex non-linear application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Theory and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Introduction to SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will attempt to understand binary classification using a machine learning algorithm known as Support Vector Machine (SVM). Binary classification refers to classifying data into two classses or labels, typically expressed as $\\{+1,-1\\}$. This means that the outcome of our machine learning algorithm will be one of two possibilities. SVM works by creating a hyperplane that seperates the data. In the case of binary classification, the SVM seperates the data into two classes that best represent the data. So when training this classifier, we need to ensure that the examples with **positive labels** are on the **positive** side of the plane, and examples with **negative labels** are on the **negative** side of the hyperplane:\n",
    "\n",
    "$$\n",
    "\\tag{1}\n",
    "\\left\\langle{w}, {x}_{n}\\right\\rangle+ b \\geqslant 0 \\quad \\text { when } \\quad y_{n}=+1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tag{2}\n",
    "\\left\\langle{w}, {x}_{n}\\right\\rangle+ b<0 \\quad \\text { when } \\quad y_{n}=-1\n",
    "$$\n",
    "\n",
    "where $x_n$ and $y_n$ refers to the input and label of the $n^{th}$ sample respectively, $w$ refers to the weights or parameters of the hyperplane, and $b$ refers to the intercept.\n",
    "\n",
    "The main objective of an SVM is to find a hyperplane that best seperates the data. To do this mathematically, we define a concept called **margin**, which refers to the distance between the hyperplane and the closest examples in the dataset, known as ***support vectors***. Below is a visualization of this taken from a very useful tutorial on SVM by Dr. Saed Sayad [1]. This picture shows how data with two labels, represented by the colors green and red, are seperated based on their features, $X_1$ and $X_2$ using a hyperplane between the support vectors.\n",
    "\n",
    "![SVM_1](https://user-images.githubusercontent.com/55256265/66949986-80fc8600-f025-11e9-8eef-3e225076d5cb.png)\n",
    "\n",
    "For our SVM classifier to be successful, we want our examples to be at least distance *r* from our hyperplane. In other words, our **positive** examples, with label of +1, would be distance *r* away from the hyperplane in the **positive direction**, and our **negative** examples, labeled -1, would be distance *r* away from the hyperplane in the **negative direction**. This objective can be formulated as:\n",
    "\n",
    "$$\n",
    "\\tag{3}\n",
    "y_{n}\\left(\\left\\langle{w}, {x}_{n}\\right\\rangle+ b\\right) \\geqslant r\n",
    "$$\n",
    "\n",
    "Since the direction of the data is our main interest, we add the assumption that the parameter vector $w$ is of unit length when utlizing the *Euclidean norm*:\n",
    "\n",
    "$$\n",
    "\\tag{4}\n",
    "\\|{w}\\|=\\sqrt{{w}^{\\top} {w}} = 1\n",
    "$$\n",
    "\n",
    "With the above assumption, we can think of distance $r$ as a scaling factor of a vector of length 1. Collecting this into a single optimization objective we obtain:\n",
    "\n",
    "$$\n",
    "\\tag{5}\n",
    "\\begin{array}{cl}{\\max _{{w}, b,{r}}} & {\\underbrace{r}_{\\text {margin }}} \\\\ {\\text { subject to }} & {\\underbrace{y_{n}\\left(\\left\\langle{w},{x}_{n}\\right\\rangle+ b\\right) \\geqslant r}_{\\text {data fitting }}, \\underbrace{\\|{w}\\|=1}_{\\text {normalization }}, \\quad r>0}\\end{array}\n",
    "$$\n",
    "\n",
    "which aims to maximize the margin $r$ while ensuring that the training data is on the correct side of the hyperplane and the parameter vector is normalized. Based on the above equation, we can see that training an SVM is merely an optimization problem! However, the above representation is not the common representation of an SVM training algorithm. To obtain the commonly used representation, we consider example $x_a$ which has an orthogonal projection onto the hyperplane, denoted by the vector ${x}_{a}^{\\prime}$. Mathematically, we can represent our sample $x_a$ by the following equation:\n",
    "\n",
    "$$\n",
    "\\tag{6}\n",
    "{x}_{a}={x}_{a}^{\\prime}+r \\frac{{w}}{\\|{w}\\|}\n",
    "$$\n",
    "\n",
    "Since ${x}_{a}^{\\prime}$ is the orthogonal projection of $x_a$ onto the hyperplane, it must lie on the hyperplane. Mathematically, this is represented by:\n",
    "\n",
    "$$\n",
    "\\tag{7}\n",
    "\\left\\langle{w},{x}_{a}^{\\prime}\\right\\rangle+ b=0\n",
    "$$\n",
    "\n",
    "By substituting $6$ into $7$, we obtain:\n",
    "\n",
    "$$\n",
    "\\tag{8}\n",
    "\\left\\langle{w},{x}_{a}-r \\frac{{w}}{\\|{w}\\|}\\right\\rangle+ b=0\n",
    "$$\n",
    "\n",
    "Since the inner product is bilinear, we can simplify the above equation to:\n",
    "\n",
    "$$\n",
    "\\tag{9}\n",
    "\\left\\langle{w},{x}_{a}\\right\\rangle+ b-r \\frac{\\langle{w}, {w}\\rangle}{\\|{w}\\|}=0\n",
    "$$\n",
    "\n",
    "If we scale our axes so example $x_a$ lies on the margin and is orthogonal to our hyperplane, we can make the following mathematical observation:\n",
    "\n",
    "$$\n",
    "\\tag{10}\n",
    "\\left\\langle{w}, {x}_{a}^{\\prime}\\right\\rangle+ b=0\n",
    "$$\n",
    "\n",
    "We also know, from the rules of the inner product, that $\\langle{w}, {w}\\rangle=\\|{w}\\|^{2}$. This, along with the subtitution of 10 into 9, results in the following identity:\n",
    "\n",
    "$$\n",
    "\\tag{11}\n",
    "r=\\frac{1}{\\|{w}\\|}\n",
    "$$\n",
    "\n",
    "Using the above identity, we can simplify $5$ as follows:\n",
    "\n",
    "$$\n",
    "\\tag{12}\n",
    "\\begin{array}{l}{\\max _{{w}, b} \\frac{1}{\\|{w}\\|}} \\\\ {\\text { subject to } y_{n}\\left(\\left\\langle{w}, {x}_{n}\\right\\rangle+ b\\right) \\geqslant 1 \\quad \\text { for all } \\quad n=1, \\ldots, N}\\end{array}\n",
    "$$\n",
    "\n",
    "Instead of maximizing the reciprocal of the norm, the usual notation is to minimize the squared norm, which results in the same thing! This notation is a convex quadratic programming problem. A constant of $\\frac{1}{2}$ is also included to yield a tidier form when computing the gradient. This makes our objective function as follows:\n",
    "\n",
    "$$\n",
    "\\tag{13}\n",
    "\\begin{array}{l}{\\min _{{w}, b} \\frac{1}{2}\\|{w}\\|^{2}} \\\\ {\\text { subject to } y_{n}\\left(\\left\\langle{w}, {x}_{n}\\right\\rangle+ b\\right) \\geqslant 1 \\quad \\text { for all } \\quad n=1, \\ldots, N}\\end{array}\n",
    "$$\n",
    "\n",
    "This expression in $13$ is known as the **Hard Margin SVM** because its formulation does not allow for any violation of the margin conditions. In other words, this forumation assumes that the data is linearly sperable, which is often not the case in real world applications. This issue is solved by what's known as *Soft Margin SVM*, which \"softens\" the constraints on the margin to allow some examples to fall within the margin region. While this may seem problematic to our classification accuracy, it is merely the price of having data that is not linearly seperable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Soft Margin SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where data is not linearly seperable, which is the case in a lot of real-world applications, we have to allow some of our examples to fall within the margin region or even on the wrong side of the hyperplane. This model, that allows for some classification error, is known as a **Soft Margin SVM**. To do this, we introduce a slack variable, $\\xi_{n}$, corresponding to each example-label pair $(x_n,y_n)$ that allows a particular example to be within the margin or on the wrong side of the hyperplane. Adding this slack variable to our objective function yields:\n",
    "\n",
    "$$\n",
    "\\tag{14}\n",
    "\\begin{array}{cl}{\\min _{{w}, b,{\\xi}}} & {\\frac{1}{2}\\|{w}\\|^{2}+C \\sum_{n=1}^{N} \\xi_{n}} \\\\ {\\text { subject to }} & {y_{n}\\left(\\left\\langle{w}, {x}_{n}\\right\\rangle+ b\\right) \\geqslant 1-\\xi_{n}} \\\\ {} & {\\xi_{n} \\geqslant 0}\\end{array}\n",
    "$$\n",
    "\n",
    "for $n = 1, ... , N$.\n",
    "\n",
    "The parameter $C > 0$ is known as the *regularization parameter* which decides the trade off between the size of the margin and the amount of slack we have. In other words, the $C$ value determines the influence of misclassification on the objective function. A large $C$ value will prompt the choice of a smaller-margin hyperplane (as long as the data is being classified correctly) while a smaller $C$ value will prompt the choice of a larger-margin hyperplane even if that hyperplane missclassifies some of the samples. Below is another useful visualization of this taken from [1].\n",
    "\n",
    "![SVM_2](https://user-images.githubusercontent.com/55256265/66952435-a049e200-f02a-11e9-8e7c-5460c49be7f7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Loss function Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to formulate the optimization function of the SVM is through considering a loss function approach. The loss function describes the error that is made on the training data. The common loss function used for SVM is known as **hinge loss** which is formulated as follows:\n",
    "\n",
    "$$\n",
    "\\tag{15}\n",
    "\\ell(t)=\\max \\{0,1-t\\}\n",
    "$$\n",
    "\n",
    "Using this hinge loss function allows us to formulate an unconstrained optimization problem for SVM as follows:\n",
    "\n",
    "$$\n",
    "\\tag{16}\n",
    "\\min _{{w}, b} \\underbrace{\\frac{1}{2}\\|{w}\\|^{2}}_{\\text {regularizer }}+\\underbrace{C \\sum_{n=1}^{N} \\max \\left\\{0,1-y_{n}\\left(\\left\\langle{w}, {x}_{n}\\right\\rangle+ b\\right)\\right\\}}_{\\text {error term }}\n",
    "$$\n",
    "\n",
    "In principle, this optimization problem can be solved with methods similar to gradient descent. However, in practice, SVM is formulated using the concept of duality explained in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dual SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way of viewing SVM is using the *dual view*, also referred to as **dual SVM**. The main benefits of the dual SVM is its independence of the number of features as well as its compatibility with kernels, which will be discussed in the next section. To represent the dual SVM, we consider the Lagnrange multipliers for the two constraints in the soft margin svm in $14$. We use the Lagrange multiplier $\\alpha_{n} \\geqslant 0$ corresponding to the constraint that examples are correctly classified, $y_{n}\\left(\\left\\langle\\boldsymbol{w}, \\boldsymbol{x}_{n}\\right\\rangle+ b\\right) \\geqslant 1-\\xi_{n}$, and $\\gamma_{n} \\geqslant 0$ to represent the non-negativity constraint, $\\xi_{n} \\geqslant 0$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\mathfrak{L}(\\boldsymbol{w}, b, \\xi, \\alpha, \\gamma)=& \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{n=1}^{N} \\xi_{n} \\\\ &-\\sum_{n=1}^{N} \\alpha_{n}\\left(y_{n}\\left(\\left\\langle\\boldsymbol{w}, \\boldsymbol{x}_{n}\\right\\rangle+ b\\right)-1+\\xi_{n}\\right)-\\sum_{n=1}^{N} \\gamma_{n} \\xi_{n}  \\end{aligned}\n",
    "\\tag{17}\n",
    "$$\n",
    "\n",
    "Differentiating the above with respect to the three primal variables, ${w}$, $b$, and $\\xi$, yields:\n",
    "\n",
    "$$\n",
    "\\tag{18}\n",
    "\\frac{\\partial \\mathfrak{L}}{\\partial{w}}={w}^{\\top}-\\sum_{n=1}^{N} \\alpha_{n} y_{n} {x}_{n}^{\\top}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tag{19}\n",
    "\\frac{\\partial \\mathfrak{L}}{\\partial b}=\\sum_{n=1}^{N} \\alpha_{n} y_{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tag{20}\n",
    "\\frac{\\partial \\mathfrak{L}}{\\partial \\xi_{n}}=C-\\alpha_{n}-\\gamma_{n}\n",
    "$$\n",
    "\n",
    "Setting each of the partial derivatives to zero yields:\n",
    "\n",
    "$$\n",
    "\\tag{21}\n",
    "\\boldsymbol{w}=\\sum_{n=1}^{N} \\alpha_{n} y_{n} \\boldsymbol{x}_{n}\n",
    "$$\n",
    "\n",
    "Substituting this identity into $17$ and simplifying yields the *dual SVM*:\n",
    "\n",
    "$$\n",
    "\\tag{22}\n",
    "\\begin{array}{l}{\\min _{\\alpha} \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} y_{i} y_{j} \\alpha_{i} \\alpha_{j}\\left\\langle\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right\\rangle-\\sum_{i=1}^{N} \\alpha_{i}} \\\\ \\\\\n",
    "{\\text { subject to } \\sum_{i=1}^{N} y_{i} \\alpha_{i}=0} \\\\ \\\\\n",
    "{0 \\leqslant \\alpha_{i} \\leqslant C \\quad \\text { for all } i=1, \\ldots, N}\\end{array}\n",
    "$$\n",
    "\n",
    "The dual SVM is the common way to represent the SVM problem. The main parameter of interest here is $C$ which represents the regularization parameter. In the next section, we will look at how kernels can be used to apply the SVM to non-linear problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed by the dual SVM representation, shown in $22$, the only inner product calculated is between samples $x_i$ and $x_j$. So we can consider a non-linear function, $\\phi({x})$, which maps the original features into another space, and then calculate the inner product of these features in the new space, which might give us a better seperation of the data. To achieve this, we introduce a class of similarity functions, known as *kernels*, represented as $k\\left({x}_{i}, {x}_{j}\\right)$. Mathematically, kernels are functions $k: \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$ for which there exists a Hilbert space $\\mathcal{H}$ and the mapping $\\phi: \\mathcal{X} \\rightarrow \\mathcal{H}$ such that:\n",
    "\n",
    "$$\n",
    "\\tag{23}\n",
    "k\\left({x}_{i}, {x}_{j}\\right)=\\left\\langle{\\phi}\\left(l{x}_{i}\\right),{\\phi}\\left({x}_{j}\\right)\\right\\rangle_{\\mathcal{H}}\n",
    "$$\n",
    "\n",
    "There are several kernel functions that can be used alongside the SVM. Note that the kernel function does not change the objective of the SVM, which is to find hyperplanes. The kernel functions merely change the shape of that hyperplane to better fit the data. This textbook [2] has a great visualization of some of the popular kernels used with SVM, which can be seen in the below image.\n",
    "\n",
    "![SVMkernels](https://user-images.githubusercontent.com/55256265/67108942-7e24a100-f19d-11e9-8af0-fe6851717c73.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we demonstrated how the SVM problem is formulated mathematically. Intuitively, we think of the SVM as a learning algorithm that attempts to seperate data based on their labels through a hyperplane. Two very important things to consider when implementing the SVM are the choice of kernel and the regularization parameter C. In the next section, we will demonstrate the implementation of SVM using the Scikit learn library [3] and how changing the kernel or the regularization parameter can affect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Implementation of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way SVM is implemented on python is using the Scikit learn (sklearn) library. This library allows us to perform all these calculations by calling one function in which we can specify any of the parameters of our SVM. The parameters are identified in the documentation of this library, found in [3]. To implement SVM on Scikit learn, we first import this library to the namespace using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a \"Support Vector Classifier (SVC)\" object using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmModel = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not specify any parameters in the above code, our SVM will have the default parameters set by the Scikit learn library. To display these parameters, we can simply use the print function on our SVM object variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(svmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, there are quite a few parameters that we can change. We will start by considering the two parameters, C and kernel, which have already been defined and discussed in section 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple Example of a Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a simple linear example of SVM in which we consider arbitrary two-dimensional data. Since the data is two-dimensional, it will have two features, we'll call $x_1$ and $x_2$. These two features can represent any arbitrary two-dimensional problem. Additionally, a set of labels is required to classify each sample; we will call this labels vector $y$. To demonstrate a simple example of linear SVM, we will arbitrarily declare our data and labels as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1, 5, 1.5, 8, 1, 9, 2.1, 9.3, 0.7, 7.3]\n",
    "x2 = [2, 8, 1.8, 8, 0.6, 11, 3.2, 10.5, 2.5, 8.9]\n",
    "y = [0,1,0,1,0,1,0,1,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a common implementation of binary classification labels using the numbers $0$ and $1$ as opposed to $-1$ and $1$. Let's take a look at our data. To do this, we are going to use the \"matplotlib\" library which has many handy tools for graphics and visualization! We are going to use the pyplot class which allows us to plot data in various ways. We are also going to color our samples based on their labels. Let's choose the color green for label of 0 and the color red for label of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19e2924ca90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "colors= ['red' if i == 1 else 'green' for i in y]\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(x1,x2,c=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the visualization of our data, we can clearly see that it is seperable by a diagonal line. This means that our data is linearly seperable. One way we can seperate this data is by plotting the line $x_{2}=8-\\frac{4}{3} x_{1}$. I'm going to do this with the help of the numpy library [4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19e292b5588>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_l = np.array(range(10))\n",
    "y_l = 8 - (4/3)*x_l\n",
    "\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(x1,x2,c=colors)\n",
    "plt.plot(x_l,y_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the above figure that our line indeed seperates our data. Theoretically, however, there are infinite lines that we can plot which seperate this data. The SVM method finds the most ideal hyperplane (line in the case of 2D) which seperates the data based on the margin to the support vectors (refer to section 1.1). So let's try seperating our data using the SVM method. We are going to use the SVC function introducted earlier, but because we are implementing a linear SVM, we will specify our kernel value as linear. The rest of the parameters will remain as default for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmModel = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our SVM model, we can train it using the \"fit\" function associated with this class. the fit function takes two inputs, $X$ and $Y$, corresponding to the input and output data respectively. So first, we have to combine our input data into one matrix using the \"asmatrix\" function from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.asmatrix( [x1,x2] )\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our input data, $X$, is a $2 \\times 10$ matrix. However, the majority of machine learning libraries in python, including Scikit learn, define the input data as (samples, features). As a result, we will have to transpose our input matrix to get our input data in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.transpose(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is in the correct format, we can use the \"fit\" function to train our SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmModel.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our SVM model is trained, we can extract the parameters, or the coefficients, of the SVM as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.36406975]\n",
      "[0.1844197 0.3052464]\n"
     ]
    }
   ],
   "source": [
    "intercept = svmModel.intercept_   #This is the \"y-intercept\" of our SVM hyperplane (line)\n",
    "w = svmModel.coef_ [0]  #Here, w is a vector containing the coefficients of the SVM hyperplane\n",
    "\n",
    "print(intercept)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above output, we can see that the intercept, $w_0 = -2.364$ and our coefficients are $w_1 = 0.1844$ and $w_2 = 0.3052$. This means that the predicted output of our SVM, $y_{predict}$ is:\n",
    "\n",
    "$$\n",
    "y_{\\text {predict}}=w_{0}+w_{1} x_{1}+w_{2} x_{2}\n",
    "$$\n",
    "\n",
    "Where $x_1$ is the first feature and $x_2$ is the second feature of our input data. Since this is a two-dimensional problem, our SVM hyperplane is actually a line whose slope can be calculated as:\n",
    "\n",
    "$$\n",
    "\\text {slope}=m= -\\frac{w_{1}}{w_{2}}\n",
    "$$\n",
    "\n",
    "And the y-axis intercept, in this case the $x_2$ intercept, is calculated as from the SVM hyperplane intercept as:\n",
    "\n",
    "$$\n",
    "x_{2} \\text { intercept }=b=-\\frac{w_{0}}{w_{2}}\n",
    "$$\n",
    "\n",
    "Now we can plot our SVM line by plotting the function $y=m x+b$ where $y$ is on the $x_2$ axis and $x$ is on the $x_1$ axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19e29379cc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = - w[0]/w[1]\n",
    "b = -(intercept/w[1])\n",
    "\n",
    "#Creating arrays to plot the SVM line\n",
    "SVMline_X = np.linspace(0,10)\n",
    "SVMline_Y = m*SVMline_X + b\n",
    "\n",
    "#Plotting our SVM hyperplane with the data\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(x1,x2, c=colors)\n",
    "plt.plot(SVMline_X,SVMline_Y, color = \"magenta\", label = \"SVM hyperplane (line)\")\n",
    "plt.plot(x_l,y_l, color = \"blue\", label = \"Initial hyperplane (line)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see in the above plot that the SVM method produces a different line than what we proposed originally. This is because the SVM finds the ideal line (or hyperplane) that is an equal distance from the support vectors (the closest points of opposing labels). Let's see what these support vectors are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1 3.2]\n",
      " [5.  8. ]]\n"
     ]
    }
   ],
   "source": [
    "support_vectors = svmModel.support_vectors_\n",
    "print(support_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the support vectors in this case are:\n",
    "\n",
    "$v_{1}=\\left[\\begin{array}{l}{2.1} \\\\ {3.2}\\end{array}\\right]$   and       $v_{2}=\\left[\\begin{array}{l}{5} \\\\ {8}\\end{array}\\right]$.\n",
    "\n",
    "This makes sense because the support vectors are the closest vectors (or data points) to the hyperplane that seperates the classes. And we can see from the graph below that the support vectors (marked with orange X) are indeed the closest points to the SVM hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19e2a3cbef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZyN5fvA8c89C8YWGUSESvaZMTO2IoMsfVVCQhRa9C1lSUVKaFUqtPz6JhVKmaIirZaxJOswyTpK1pQJyVhnzPX745593848Z+Zc79drXnPOc5bnOpOe6zzPfd/XZUQEpZRSnsfL6QCUUko5QxOAUkp5KE0ASinloTQBKKWUh9IEoJRSHsrH6QDywt/fX+rWret0GEopVaxERkb+LSJV028vVgmgbt26bNq0yekwlFKqWDHG7M9su14CUkopD6UJQCmlPJQmAKWU8lCaAJRSykNpAlBKqdw4dw5iY52OolBpAlBKqewcPQo33QQVK0LlytCiBfzyi9NRFYpiNQ1UKaWKVEICtG8Pv/4K8fF226ZN0K6d3ebv72x8BaRnAEoplZUVK+DQoZSDf5ILF2DWLCciKlSaAJRSKit799qzgPTOnoVdu4o+nkKmCUAppbISGAjGZNxerhy0bFn08RQyTQBKKZWVFi3sgb5MmZRtPj52MHjAAOfiKiSaAJRSKjvffAOjRkH16lCpEgwcaAeCy5VL+7wTJ2DGDHjxRVi/HopBu11TnHoCh4aGihaDU0q5nVWroHt3O15w/rw9Y+jeHT75BLyc/55tjIkUkdD0252PTCmlirP4eOjVyy4SO3MGLl6E06fh668hPNzp6LKlCUAppQpiwwaIi8u4/fRpeP/9oo8nDzQBKKVUQWR3Gd3NL7FrAlBKqYJo1Qp8fTNuL1cO7r676OPJA00ASilVED4+MH++PeCXLWsHfcuVgy5doG9fp6PLlstrARlj3gduAo6KSNPEbZcC4UBdYB9wu4iccHUsSinlEmFhsG8ffPopHDsGHTvCtddmvojMjbh8Gqgx5nogFpiTKgG8DBwXkcnGmLFAZREZk9N76TRQpZTKO8emgYrIKuB4us09gNmJt2cDt7o6DqWUUmk5NQZQXUSOACT+ruZQHEop5bHcfhDYGDPUGLPJGLMpJibG6XCUUqrEcCoB/GWMqQGQ+PtoVk8UkRkiEioioVWrVi2yAJVSqqRzKgEsAgYl3h4ELHQoDqWU8lguTwDGmE+AtUADY8whY8w9wGSgszFmD9A58b5SSqki5PJ1ACLSP4uHOrl630oppbLm9oPASimlXEMTgFJKeShNAEop5aE0ASillIfSBKCUUh7K5bOAlFIeKD4evv0WDh6E1q0hONjpiFQmNAEopQrX779Du3bw7782ERgDHTrAF19k3jhFOUYvASmlClffvnDkCJw6BWfP2kbpy5fDtGlOR6bS0QSglCo8f/0FW7dCQkLa7WfPwsyZzsSksqQJQClVeC5cyLoL1oULRRuLypEmAKVU4alVy/6kV7q02/fH9USaAJRShccY+PhjqFAB/PzstvLl4aqrYNw4Z2NTGegsIKVU4WrRAn77DWbPTpkR1KsXlCrldGQqHU0ASuVWwkUwXllf486MCEgCeHm7Li53VLUqPPqo01GoHOglIKVyI+EirBsCm0fZg3puiNjnrxtiX6+Um9EEoFRuGC8ofSnsnp67JJB08N893b7O6P9qyv3oJSClcsMYCJ5qb++ebn8HT838clDqg3+DEVk/TymHaQJQKrcySwK1noA5c2DfPmjb1g52bhujB39XuHABFiyAH3+EOnVg8GCoVs3pqIo1I7m9numKnRszCrgXEOAXYIiInMvq+aGhobJp06aiCk+pzKX+hr/MFz72gnPnoXw5uLsUtDqhB//CduoUtGkD+/dDbCyUKQM+PrB0KbRq5XR0bs8YEykioem3O3Zh0hhzOTAcCBWRpoA30M8V+7p4MffjdkrlyBho/hqsvQQ6xcFt5+32W0/bg//foXrwL2wvvWSnlsbG2vvnztnbd9yh/3MXgNMjUz6AnzHGBygL/OGKnUydCmFhEBXlindXHunQIXjvPHwL3AjMTfz9LTA1Rg/+hW3ePHvQT+/IEXtWoPLFsQQgIoeBV4ADwBHgpIj8kP55xpihxphNxphNMTEx+dpX1aqwfbstSX7//XD0aIFCV8ouakoQ+Cjd9o+A0mWciKhky2oRWUKCLTOh8sXJS0CVgR5APaAmUM4YMzD980RkhoiEikho1apV87WvQYNgzx4YMQLefx/q14fXXtPaVKoALrsMAprBnem2D/GBofc5ElKJdt99ULZs2m1eXtCsGdSo4UxMJYCTl4BuAH4XkRgRiQM+B651yZ6WQOV5MPUB+GUrXHcdjB5t/+18/bVeQlT5IAKTm0I37EDwvWVgqQ/cEA/t9us/qsL20EPQqZNNAn5+ttbQZZdBeLjTkRVrTk4DPQC0NsaUBc4CnQDXTPH5DHjX3mxYC77pBN+MhlFfwE03Qbdu9oygUSOX7F2VNEmzgP6cBfUfhgqdocVhWwOHD+3sIC8vHQguTL6+sGgRbNkC69fD5Zfb/3G1w1iBOJYARGS9MWY+sBmIB7YAM1yys3eAx4BliT+L4T/H7CnIW9Vg0nJo1hQeug8mvAiVK7skClUS5LTISxJ73+a0WEzlT/Pm9kcVCkfXAeRVoa0DSAB+BpYDyyBmJYw/Y7PPpT7wbEe4byT4tMfOTVIKcr/CV1cCKzfjdusAHOUFNAdGA99A1RPwv9Ww+X5oWg4e/AGC/wPLLwHCgGeBn4A450JWDsvLQT1pxXCDEbmvHaSUAzwzAaRXCmgLQf+DiBMw/yM4VR06xUOvKNj7NHAdcClwEzAV2Io9k1CeQRLg/PHcf6NPnQTOH7evV8rNeOYloFw4e9YODL/4IsTFweju8ERlqLAa2JP4pKpAB+zwdSfgSkDP9Esu7Qegiim9BJRHfn7w5JOwe7dtZfriF3DNNzD7SUjYB3wAdAVWA/cDV2NXNNwDfAz86VTkymW8vPN+Ld8YPfgrt6UJIAeXX26LPa5bB1dcYQsQtu4DaxsAHwKHgR3Am0AwdjXDAKAG0BQYASwCTjoSvlJKZUkTQC61agVr19pkcOgQXHstDBwIhw4DjYBh2IP/38BGYDJwOXb9QQ/s+EErYBx2KmqWNU+VUqpo6BhAPsTGwuTJ8Mor4O0NY8fa9qd+fpk8+TywjpQ1COuBi0Bp7MBy0vhBCNqdQSnlElmNAWgCKIDff4fHHrM9KurUgSlT4LbbcrhMfApYRUpC2Jq4vSLQnpSE0AQdUFZKFQodBHaBevVg/nyIiIBLLoHbb4f27e1q9SxVALoDr2EXo/0FzMN2QtgBjASaYccQ7gDeA/a58EMopTyWJoBCEBYGmzfDO+/Azp0QEmKLF+aq7HQ1oC+2XMWv2IP9e9izgAhsv7R6wFXAfdhkoeWslVKFQBNAIfH2hqFDbdnpkSNh1ixbdvqVV/JYdroOcDe2wcgfwDZgOnZG0adAf6A6EACMAhYD/xbiB1FKeQwdA3CRXbtsyelvvknpP9C9ewFLwsQDkaSMH6zBDjJ7Ay1JGT9ogx1kVkopdAygyDVsaHsNfPONrQx8881w4432ElG++ZB2KukJYCkwBluW4gXsyuTKQBfgJWyB7YsF2KdSqsTSBOBiN94Iv/xi+xKvW2eb0IwYASdOFMKb+2G/8T+PnWp6HFiIHSv4AxgLtAD8gZ7YxWo7geJz0qeUciFNAEXA19eOC+zZYweH33zTXhb6v/+D+PhC3NElwC3YMYNt2HIUHwO9gSjgYaAxUAvbynAWcLAQ96+UKlY0ARShqlXh7bftjKFmzWDYMNvbYtkyF+2wOnbQeCbwO/AbtulBO+B7YAhwBXAN8AAwHzjmoliUUm5HE4ADAgNh+XK7gCw2Fm64AXr2hN9+c/GOryRlKumf2HUIrwENsLOO+mArnAYDjwLfArEujkkp5RhHE4AxppIxZr4xZpcxZqcxpo2T8RQlY6BXLzso/MILsGQJNG4MTzwBp04VQQBepEwl/Qr7zf8n4BnspaQ3gP9gB5TbAROxlU/zMqVVKeXWHJ0GaoyZDawWkZnGmFJAWRH5J6vnF6dpoHn1xx/24D9nDlx2me1DcNdddgaRI85gp5kmTTmNxA4elwWuBzpiB6CD0PNIpdyc29UCMsZUxF6EuFJyGURJTgBJ1q+3s4TWr4fQUJg+3VYeddwJYAUpCWFX4vZLSdsUpz5aw0gpN+OO6wCuBGKAD4wxW4wxM40x5dI/yRgz1BizyRizKSYmpuijLGKtWsFPP8GHH9qzguuugwEDbAlqR1Um7VTSQ8Ac4GZgA/AgdizhCmAwtlfCH04EqpTKLSfPAEKxs9evE5H1xpjpwL8iMj6r13jCGUBqsbHw0ku2yqi3N4wZY8tOly3rdGTpCLaOUdLZQQQps4kaknJ2EIZNJEqpIuWOZwCHgEMisj7x/nzs/BOVqHx5ePZZW1aie3eYMAEaNYLwcNtq1m0Y7KWf/wKfYYvVbQFewRaymwX0AqoAodiVyz9gxxmUUo5xLAGIyJ/AQWNMg8RNnbAFkVU6devCp5/CihVQuTL06wfXX2/XE7glL+zg8GjgG+wK5dXABOwg8lRsP+XK2LOCZ7EzkOIciFUpD+b0/I2HgbnGmK3YQ8YLDsfj1tq3h8hImDHDNqsPDbUri//6y+nIclAKaItNAKuwA8rfAsOxlUwnYLujXQrcREqvhAQnglXKc2g10GLqn3/s5aHXX7etKJ9+GoYPh1KlnI4sH46RdoZRdOL2qqSdYXQlOsNIqXxwxzEAVQCVKsGrr8K2bfZy0GOPQdOm8NVXbjY+kBtVsPWK/g/Yja1PNAvoBvwI3A9cjR1PuAdb3+hPJwJVqmTRBFDMNWgAixfDt9/amUK33ALdusGO4jyaUgsYhJ1megg77fRN7BSBz4EB2JaZTbCXkRYCJx2JVKliTRNACdGtG2zdCtOmwYYNEBBgLwkdP+50ZAVksFNJh2EP/n9jexy8hE0UM4FbseMHqXslnHUiWKWKF00AJYivr11FnFR2+q23XFR22kneQAjwOLaiadIK5SexDXNeBm7AzjDqSEqvhJLy+ZUqRJoASiB/f1t2essWW3nU5WWnnVQaaI8tYrcGmxAWY1cmHwOewrbIrELaXgnFbZxEKRfQBFCCBQTYg/7nn8Pp00VYdtpJFYDupEwl/Qtb/rofdpXJSKAZdgzhDuA9YJ8TgSrlPE0AJZwx9qC/Y4etMJpUdnrs2CIqO+20akBf4B1suYrfsQf9TtiSFfdiZxddBQwFwrErmZXyALoOwMP88QeMGwezZ0P16jYpDBrkYNlpJwl2hlHS+oMVpMwmakbK+oPrgYoOxKdUIdF1AAqAmjVh1ixbbrpePbj7bmjZEtascToyBxhsj+SHgS+xM4zWY9ejVwPexlY7vRS4FhiPTRLnHYhVKRfQBOChWra0Zac/+gj+/BPatoU77oCDntwk3gdoCTwBLAX+wZ4ZjMGWpXgBuzK5MtAFmAxsBC46EaxSBaeXgBSnT6eUnTbGlp1+7DE3LDvttJPYWkZJl4y2JW6vhC1ql3TJqCFaskK5FbfrCJYfmgBca/9+ePxxW3m0dm2bEG6/3SYFlYm/gOWkJIR9idtrkNIysxO2SY5SDtIxAJWjOnVsr4GVK6FKlZSy05GRTkfmpqoD/bGrkX8HfgNmYAeNfwDuBuqQtlfC345EqlSmNAGoDK6/HjZtSik73aIF3HtvMSg77bQrgfuw6w7+BLZiex80xBawux07uNwceBRbEjvWkUiVAjQBqCx4e9tyEnv2wCOPwJw5tqzElClwXmfB5MwLO5V0JPAVtinOT9gVy5WAN4D/YAeU2wETsU1zLjgQq/JYOgagciU6GkaPtpVHr7oKXnsNbr5Zxwfy7Qy2dMVy7IyjSOy6hLLYhJA0fhCEfk1TBaZjAKpArrnG9hr49ltbdK5HD+jaFbZvdzqyYqos0Bl4ETuV9Bi22undwAFssbsQbFOc27BrEqLRGkaqUDmeAIwx3saYLcaYxU7HonKWVHZ6+nTYuNEWm3v44RJQdtpplYGe2EtDO4DDwIfYAnYbsMXtGmBnFA1OfOywE4GqksTxBACMwC7IV8WEr6/tNbBnDwwdastN169vy0+XmLLTTqsJDAQ+APZjv/2/ja1suhi4C9sPIXWvBE3CKo8cTQDGmFrY2o0znYxD5Y+/vz34R0VBUBA89JD9vWSJ05GVMIaUqaSfYovVbQFewc48mo1tqekPhJLSK+GME8Gq4sTpM4Bp2H+uCQ7HoQqgWTNYuhS++ALOnoUuXewYwa+/Oh1ZCeWFHRweDXyD/ea/GpiAHVuYhu2nXIm0vRLinAhWuTPHEoAx5ibgqIhku8zIGDPUGLPJGLMpJiamiKJTeWUM3HqrHRR+8UVYvtyWnR4zBv791+noSrhSQFtsAliFbYrzHXYKaix2imlbbFG71L0S9GuXx3NsGqgx5kXgTmyzvjLYgrufi8jArF6j00CLjyNHbNnpWbNs2ekXXoDBgz207LTTjmGrmCaVrIhO3O6PLW6XNOX0KrSGUQnl1rWAjDFhwKMiclN2z9MEkIOEi2C88jY5XwQkAby8XRLSxo22T/HatRAcbGcPtW3rkl2p3DpESjJYBvyRuP0KUpJBJ+AyR6JTLpCvdQDGmIrGmKsy2R5QmMGpQpBwEdYNgc2j7EE9N0Ts89cNsa93gRYtbK+BuXNtKYl27aB/fzhwwCW7U7lRCxgEzMEmg53Am9h1B19gZx/VAJoAw4GFpDTKUSVKlgnAGHM7sAtYYIzZboxpkerhWYUZhIisyOnbv8qB8YLSl8Lu6blLAkkH/93T7euM667NGGN7DezeDU8/DV9+CQ0bwsSJcEZnqjjLkHYq6d/AJuAlbKKYCdyKHT9oBYzDnjWcdSJYVdiy+79+HBAiIkHAEOBDY0yvxMf0SqG7MQaCp0KDETkngdQH/wYj7OuKoKZDuXIwaRLs2mXLSEyaZBPBvHm5P2lRLuaNPRNImkp6Ajt+8CS2Yc4U4AbswrWOwPPAOuxInip2sksAPiJyBEBENmCHi540xgxHF6S7p0ySwJkLp/l85+d88ssnHDtzzLGDf2pJZadXrbJrCfr3t5eGtOy0GypN2qmkx4GvsWcMx4GnsIvTqmBXLU/HNsrRI0SxkOUgsDHmJ+BOEfkt1bYK2O6pbUWkdNGEmEIHgXMp1UH+rX99GXeiDALEJVxgffNrCfgnwrGDf3oXL9qZQuPGQUyMnSn0wgtwmQ5AFg8xQAQpA8pJR4vq2DOEpMY49RyJTiXKzyDwGNJd6hGRU9glJs8XbniqUBnDqSbP8Na/PgyrGMekiqc4deEUL1Y6T8A/ERy7YqBbHPzBlp2+556UaqMffWQLz738spadLhaqYvscvAP8iu2K9h72MlEEtj/ClaTtlXDUiUBVZrJLALOB3sYYn6QNxpjq2OokN7s6MFUwi/d8zRMnyjDtBIysDFLf/n79H8OUszXd4uCf2iWX2F4D27dDWJhdQNakCSxcqOMDxUodbEXTj7DTS7cDrwMB2I5o/bFnBwHAKGyvBF0o6JjsEkAI9sRtizGmozFmBLYu4VrsfADlxs7EnSFBhFHpWhCOiBFi4047E1Qu1K8PixbBd99BqVJ2dXHnzrBtW86vVW7GAI2Bh7EXjv8G1gMvYDuj/Q87bnApdhzhKexZwzkngvVMWSYAETkhIv/FTgRbCjwGXCcib4mILiJ3c12v7spFiWeqf9rtb1b3oWeDW50JKg+6doWff4bXX7eDw4GBttjcsWNOR6byzQdoCTyBPaKcwDbEGZv4+GTsmEFlbK+EydheCa5ZoqLIfh1AJWPMO9gpoN2A+cC3xpiORRWcyr9aFS5nZbMQRlaG6f+A2UPimEA8HU98VSyuq/j62l4Dv/4KDzwAb79tzxDeeAPitLBZ8VcGO7fwOex1hePAImzV07+wiaIltmRFT+xitZ3oDKNClN0soL3A/wHTRCQ+cVtQ4rb9ItK/yKJMpLOAcinVLKA/L+/Hs6cqc/biOW5v3IeuJ7/DRL/uNrOA8uKXX2DUKFi2zBaamzbNXh5SJdRfpJ1h9Hvi9pqkzC7qiC1hobKV51pAxphaInIoi8fuE5F3CznGHGkCyIWc5vm7wTqAghCxYwSPPAJ799oFZa++as8MVAn3OynJYDkps4muJqV+UQfsGYNKw62LweWWOyWA2Aux/HHqD2pVrEVZ37JOh2Pl9uBezJMA2Cmi06fDs8/a2yNHwlNPQcWKTkemioRgF5wlJYSVwKnEx4JISQjtgPJOBOhetCl8IbmYcJFHvn+EqlOqEjIjhKpTqvLU8qdwPJHm5aCel7IRbqp0aXj8cduWcuBAeOUVexbw3nt2cZkq4QzQDNvz4CtsyeufgGexjXDeAP6DHVBO3SvhghPBui9NAHn03KrneCfyHc7FnyP2Qixn4s4wdd1Upq+f7mxgkgDnj+f+G33qJHD+uH19MXTZZfD++7BhA1x9Ndx7r61Aunq105GpIuVL2qmk/wBLgEexB/3nsCUtKmOntEwBIvH4GUZ6CSgPRITKL1Xm5PmMtXFrVqjJ4UcOOxBVKm7YD6AoidjCco8/DocOQd++dkXxFTpIqP4hbVOcnYnbK5O2Kc41lMhSl3oJqBAkSEKmB3+AmNNu0K7Syzvv1/KNKREHf7AfpX9/W210wgS7irhBA3v7tPuufVNFoRK2rPUbwA7gMHa18q3Y8tfDsGWxryClV4LD3+eKgiaAPPD28qZBlQaZPhZ0WVARR6OyUq6c7TWwe7ddSfzMM7bs9McfF7uhDuUqNYEBwPvY+kV7sCuT22CrnQ7C9kNI6pWwALtOoYTRBJBHr9/4OmV9Umb9GAxlfcsytetUB6NSmbniCvjkE1t2ulo1GDDAtqN0k4lkyl0Y7FTS+4FPsdNLtwCvYIvYzQZuw04vTd0roQScVeoYQD6sPbiWSSsnsfPvnQRWD2RC+wmE1AxJ85xz8ecI3xbO2kNruabKNQwKHESVslUcilhdvAizZ8MTT8DRoyllp2vUcDoy5fYuYEtSJI0frAXiSBl4Tho/aJm4zQ253ToAY0xt7JW2y4AEYIaIZDuVxl0SQE6OnTlGi3dbcPT0UU7HncbPxw9fb19WDV5F4GWBTofn0f79F557zq4iLl3arh0YOdLeVipXTgM/kpIQtmDXJZQHriclITTDba6xuOMgcDwwWkQaAa2BYcaYxg7GU2jGR4zn8L+HOZ1YdfNs/Fn+Pf8vd315l8ORqYoV7cyg7duhY0cYO9aWlfjySx0fULlUDugKvIydShqDrZR2J7YnwmjsYrTqQF9gBrZRjhv++3IsAYjIERHZnHj7FHZi1uVOxVOYPt/5ORcSMq442fX3Lo6fzXkk6bfjv9FjXg/Kv1Ce6lOqMyFiAhcu6gqWwlS/vp0l9MMPUKYM9OwJN9xg6w0plSdVgN7YKmm7gYPYcYP/YNto3o8dY6iL7ZUwFzjiRKAZucUJijGmLtAcWy08/WNDjTGbjDGbYmLcYKplLvh6Z34hUETw8fLJ9LEkR08fpcW7LVgcvZjTcac5euYoU36awh0L7nBFqB6vc2dbdvqNN2DLFggKgmHD4O+/c36tUpmqBdyFTQIHgV3AW0Aoti/CQOwspCbAcGAhdp2CAxxPAMaY8thJViNFJENvIBGZISKhIhJatWrVog8wH+5pfg9+Pn5ptnkbb9rVaUfF0tkXq3lrw1ucjT9LQqqVuWfjz/L1nq/57fhv2bxS5ZePj+01sGcPPPggvPOOPUN4/XUtO60KyAANgAexR7kY7LqDl7CJYiZ2LUIV0vZKOFs04TmaAIwxvtg/y1wR+dzJWArTE22foE3tNpTzLYefjx8VSlXgikuuYM6tc3J87YbDGzgXn7ElUinvUmw7qm2xXKlKFXsmEBUFoaEwYoRtRPP9905HpkoMb9JOJT2BLWT3FFAKO/W0M3aFckds9/V12BFTF3AsARhjDLZ99E4Rec2pOFyhtE9plt21jIhBEUztOpXP+nzGnof3cHnFnIc4mlZrSinvUhm2xyfEc/WlV7siXJVO06Z2bGDhQrhwAbp1s2Wno6OdjkyVOKWxM4cmYWcWHccuRBuWePsp7FTTKtiEUcicnAbaFlgN/IKdBgowTkS+yeo1xWUaaEHs/2c/Td9uSuyF2ORtpb1L06ZWGyIGRzgYmWc6f95eCnr2WTh3DoYPh/HjbRN7pVzub1Ka4jwB1Mnf27jdNFAR+VFEjIgEiEhQ4k+WB39PUadSHSIGRRB8WTDexpvS3qXp27Qvi/ovcjo0j1S6NDz2mP32f+ed8Nprdnxg5kwtO62KgD/QB1umIp8H/+zoSmA3di7+HL5evniXkGJtJUFkpB0bWLPGzhiaPh2uv97pqJTKntudAaiclfEpowd/NxMSYnsNfPKJnSravj3cfjvs3+90ZErlnSYApfLIGOjXz1YbnTgRFi+21UafflrLTqviRROAUvlUtqztNbBrl11J/Oyztv/A3LlaVkIVD5oAlCqgK66wvQZWr7YtKgcOhOuug40bnY5MqexpAlCqkLRta3sTv/8+7N0LLVvastNH3KTui1LpaQJQqhB5ecGQIXba6JgxdrD4mmvgxRftOgKl3IkmAKVcoGJFmDzZlp3u1AnGjbNlp7/4QscHlPvQBOBCFy5eYO+JvWlW9SrPcvXVttfAkiV20LhXLy07rdyHJgAXmbZuGv4v+xPwdgBVp1Tlv4v/S9xFLS3pqW64wRaZe/NN+zsoyFYe1bLTykmaAFwgfFs4Ty5/klMXTnE67jTn4s8x5+c5PPL9I06Hphzk42N7DezZY3/PmGHLSkyfrmWnlTM0AbjAc6uf40zcmTTbzsaf5b0t73E+/rxDUSl3cemltsDczz9Dixa2J3FAAHz3ndORKU+jCcAF/jj1R6bbBeHk+ZNFHI1yV02a2F4DixZBfDzceCPcdJOWnVZFRxOAC7S6vBUGk2F7xdIV8S/r70BEyl0ZY3sNbNtmm9WvWmUTw6OPwkn9rqF4uN8AAB44SURBVKBcTBOAC7zY6UXK+pZNkwTK+pbl1S6v4mX0T64ySio7vWcPDBqUUnb63Xe17LRyHT0auUDgZYGsvWcttza8lcsrXE7b2m35ou8XDAwY6HRoys1Vr257DWzaZOsKDR1q21OuWuV0ZKok0n4ASrkpEfj0U3tmcPAg9OljLxPVret0ZKq4cct+AMaYbsaY3caYX40xY52MRSl3Ywz07WurjU6alFJ2evx4LTutCoeTTeG9gbeAG4HGQH9jTGOn4lHKXZUta3sN7N5tVxI/95y9PPTRR5CQkPPrlcqKk2cALYFfRWSviFwA5gE9HIxHKbdWu7YtO/3jj7bs9J132rLTGzY4HZkqrpxMAJcDB1PdP5S4LQ1jzFBjzCZjzKaYmJgiC04pd5V00H//ffj9d2jVypad/iPz5SdKZcnJBJBxojxkGJEWkRkiEioioVWrVi2CsJRyf1p2WhUGJxPAIaB2qvu1AP0Oo1QeJJWd3rEDOndOKTv9+edadlrlzMkEsBGob4ypZ4wpBfQDFjkYj1LF1lVX2V4DSWWne/e2fQi2bnU6MuXOHEsAIhIPPAR8D+wEPhWR7U7Fo1RJkFR2+q23bLG55s3hgQdAh89UZhxdByAi34jINSJylYg872QsSpUUPj6210BS2el337VlJaZN07LTKi0tBaFUCZVUdnrrVjtTaNQoLTut0tIEoFQJ17ixPeh/9VVK2enu3e3CMuXZNAEo5QGMsb0Gtm+HKVPsYrKmTWH0aPjnH6ejU07RBKCUBylVyvYaiI62i8emTrXjAzNmaNlpT1Tsq4HGxcVx6NAhzunqF+UCZcqUoVatWvj6+jodikts2QIjRsDq1RAYaAeKw8KcjkoVtqyqgfo4EUxhOnToEBUqVKBu3boYk9niYqXyR0Q4duwYhw4dol69ek6H4xLNm8PKlfDZZ7bsdIcOcNtt9jKRlp0u+Yr9JaBz585RpUoVPfirQmeMoUqVKiX+7NIYuP12W3b6mWfg669t2emnnoLYWKejU65U7BMAoAd/5TKe9G/Lz8/2Gti9264kfv55W3b6ww+17HRJVSISgFKq8NSuDXPnwpo1ULMm3HUXXHstrF/vdGSqsGkCKATPP/88TZo0ISAggKCgINavX8/EiRN54okn0jwvKiqKRo0aAVC3bl3atWuX5vGgoCCaNm2a4f1XrFjBTTfd5LoPkAf79u3LNMbCNm3aNObMmQPA4MGDmT9/PgD33nsvO3bsyNd7Ll68mAkTJhRajCVd0kF/1izYvx9at7bJQMtOlxyaAApo7dq1LF68mM2bN7N161aWLl1K7dq16d+/P+Hh4WmeO2/ePO64447k+6dOneLgQdsSYefOnUUad3bi4+Md3//777+f5m+VZObMmTRunL/Gcd27d2fRokWcOXOmoCF6DC8vGDTIThsdOxbCw23Z6Rde0LLTJUHJSgAjgbBC/hmZ/S6PHDmCv78/pUuXBsDf35+aNWvSoEEDKlWqxPpU582ffvop/fr1S75/++23JyeJTz75hP79+2e5n9jYWG677TYaNmzIgAEDEBGWLVtGz549k5+zZMkSevXqBUD58uUZPXo0wcHBdOrUiaRmOr/99hvdunUjJCSEdu3asWvXLsB+y37kkUfo0KEDY8aMYeLEidx555107NiR+vXr8+6772aIad++fbRr147g4GCCg4P56aefAHvGEhYWliFegMjISNq3b09ISAhdu3blyJEjGd53+fLlBAcH4+OTcZJaWFgYSVOBy5cvz5NPPklgYCCtW7fmr7/+AiAmJobevXvTokULWrRowZo1awB7PT8sLIzFixdn+XdWmatQwfYa2LkTunSBJ5+ERo1gwQItO12clawE4IAuXbpw8OBBrrnmGh588EFWrlyZ/Fj//v2ZN28eAOvWraNKlSrUr18/+fHbbruNzz//HICvvvqKm2++Ocv9bNmyhWnTprFjxw727t3LmjVr6NixIzt37kw+uH/wwQcMGTIEgNOnTxMcHMzmzZtp3749kyZNAmDo0KG88cYbREZG8sorr/Dggw8m7yM6OpqlS5fy6quvArB161a+/vpr1q5dyzPPPMMf6c79q1WrxpIlS9i8eTPh4eEMHz4823jj4uJ4+OGHmT9/PpGRkdx99908+eSTGT7rmjVrCAkJyfFvf/r0aVq3bs3PP//M9ddfn5ykRowYwahRo9i4cSMLFizg3nvvTX5NaGgoq1evzvG9VeauvNL2Gli2zCaF226zU0d//tnpyFR+FPt1AGlMK/pdli9fnsjISFavXk1ERAR9+/Zl8uTJDB48mH79+nHttdfy6quvMm/evAzf8C+99FIqV67MvHnzaNSoEWXLls1yPy1btqRWrVqAHSvYt28fbdu25c477+Sjjz5iyJAhrF27Nvm6uZeXF3379gVg4MCB9OrVi9jYWH766Sf69OmT/L7nz59Pvt2nTx+8vb2T7/fo0QM/Pz/8/Pzo0KEDGzZsICgoKPnxuLg4HnroIaKiovD29iY6OjrbeCtVqsS2bdvo3LkzABcvXqRGjRoZPuuRI0eSx0qyU6pUqeSxkZCQEJYsWQLA0qVL04wT/Pvvv5w6dYoKFSpQrVq1DIlM5V3HjrB5s600On48BAfDfffBs8+CNu4rPkpWAnCIt7c3YWFhhIWF0axZM2bPns3gwYOpXbs2devWZeXKlSxYsIC1a9dmeG3fvn0ZNmwYs2bNynYfSZeYkvaXdJ1+yJAh3HzzzZQpU4Y+ffpketkE7OWPhIQEKlWqRFRUVKbPKVeuXIbXZHd/6tSpVK9enZ9//pmEhATKlCmTbbwiQpMmTTL9O6Tm5+eXq7n3vr6+yTGl/pskJCSwdu1a/Pz8Mrzm3LlzmW5XeefjY3sN9OsHkybBm2/CvHkwYYItQ12qlNMRqpzoJaAC2r17N3v27Em+HxUVRZ06dZLv9+/fn1GjRnHVVVclfyNOrWfPnjz++ON07do1X/uvWbMmNWvW5LnnnmPw4MHJ2xMSEpJnznz88ce0bduWihUrUq9ePT777DPArnT9OZtz94ULF3Lu3DmOHTvGihUraNGiRZrHT548SY0aNfDy8uLDDz/kYg7FZBo0aEBMTExyAoiLi2P79ow9gBo1asSvv/6aq8+fmS5duvDmm28m30+d8KKjo4tkFpMnqVzZlpDYutXOFHrkEVt2+ttvnY5M5UQTQAHFxsYyaNAgGjduTEBAADt27GDixInJj/fp04ft27enGfxNrUKFCowZM4ZSBfi6NGDAAGrXrp1mdky5cuXYvn07ISEhLF++nKeffhqAuXPn8t577xEYGEiTJk1YuHBhlu/bsmVLunfvTuvWrRk/fjw1a9ZM8/iDDz7I7Nmzad26NdHR0RnOINIrVaoU8+fPZ8yYMQQGBhIUFJQ8cJzajTfeyKpVq/LyJ0jj9ddfZ9OmTQQEBNC4cWP+97//JT8WERFB9+7d8/3eKmuNG9uD/uLFduHYf/5jfxLnGSh3JCJF/gNMAXYBW4EvgEq5eV1ISIikt2PHjgzbPM2wYcNk5syZabaVK1euQO85YcIEmTJlSoHeoyBuvfVWiY6OLtT3/PPPP6Vjx455fp3+G8u78+dFXn1VpGJFER8fkZEjRU6ccDoqzwVskkyOqU6dASwBmopIABANPJHD81UWQkJC2Lp1KwMHDnQ6lEI1efLkTKeIFsSBAweSZzgp1ypVyl4K2rMHhgyB6dNt2el33tGy0+7E8XLQxpiewG0iMiCn52ZWDnrnzp25mjGiVH7pv7GC27IFRo6EVavs+MC0aXb6qCoaWZWDdocxgLsBHS5SqgRr3hxWrLBlp0+etNNIe/eG3393OjLP5rIEYIxZaozZlslPj1TPeRKIB+Zm8z5DjTGbjDGbkhY8KaWKH2PswrGdO+16ge++s6uJn3xSy047xWUJQERuEJGmmfwsBDDGDAJuAgZINtehRGSGiISKSGhVXWGiVLHn52d7DezeDX362LpC11wDc+Zo2emi5sglIGNMN2AMcIuIaGUupTxQrVq218BPP9nbgwZBmzawbp3TkXkOp8YA3gQqAEuMMVHGmP/l9AJ3Vr58+Ryfk7qM8QsvvJDmsWuvvTZf+yiq0sy5lZu/Q0F9+eWXPPPMMwBMnDiRV155BYCnn36apUuX5us9f/nllzSL6FTRSjroz54NBw/a+3feCYcPOx1ZyedIAhCRq0WktogEJf7814k4ilLqMsbpE0Bmi6HckdNlogFefvnlNAXskjzzzDPccMMN+XrPZs2acejQIQ4cOFDQ8FQ+eXnZXgPR0TBunB0svuYaeO45OHvW6ehKLneYBVRoRo6EsLDC/RmZQzno1LIrg5xUxnjs2LGcPXuWoKAgBgywM1+TvjnHxsbSqVMngoODadasWbardJNcvHiR++67jyZNmtClSxfOnj3Lb7/9RnBwcPJz9uzZk1xds27duowZM4aWLVvSsmXL5JILWZVQnjhxIkOHDqVLly7cddddzJo1ix49etCtWzcaNGiQXGU0taw+x759+2jUqFGGeCHrMtWpRUdHU7p0afz9/TM8lrppTN26dZkwYULy/pPe6/Tp09x99920aNGC5s2bp/n73nzzzcmVW5Vzype3rSh37IBu3WyhuUaNYP58LTvtCiUqAbiDzMogpzZ58mT8/PyIiopi7ty0k5/KlCnDF198webNm4mIiGD06NHktE5jz549DBs2jO3bt1OpUiUWLFjAVVddxSWXXJJcA+eDDz5Ic4mjYsWKbNiwgYceeoiRiRkuuxLKkZGRLFy4kI8//hiADRs2MHfuXKKiovjss89IvzYju8+RWbyQfZnqJGvWrEmT2LLj7+/P5s2beeCBB5IvEz3//PN07NiRjRs3EhERwWOPPcbp06cBLRPtbq680vYaWL4cLrnEDhaHhUEWdQxVPpWoaqDTHCgHnV5WZZtzQ0QYN24cq1atwsvLi8OHD/PXX39x2WWXZfmaevXqJZdoDgkJYd++fYAdc/jggw947bXXCA8PZ8OGDcmvSSpLnVSoDrIuoQxwyy23pKmg2blzZ6pUqQJAr169+PHHHwkNTVljktXnyCrenMpUJzly5Ai5nQmW1BgnJCQkuefCDz/8wKJFi5ITwrlz5zhw4ACNGjXSMtFuqkMHiIyEmTPtzKHgYLj3XntpqFo1p6Mr/kpUAnAHWZVtzo25c+cSExNDZGQkvr6+1K1bN8eyyOn3l3RJpXfv3kyaNImOHTsSEhKSfMCGtGWdk25nV0I5r2Wis/scmcWbU5nqJH5+fpw8eTLb5yRJ2k/q/wYiwoIFC2jQoEGG52uZaPfl4wP//S/07QvPPGPLToeH27LTDz2kZacLQi8BOcDX15e4uLgM20+ePEm1atXw9fUlIiKC/fv353sfZcqUoWvXrjzwwAPJXcKSJLWhDA8Pp02bNkD2JZTTW7JkCcePH+fs2bN8+eWXXHfddQX6HLktU13QMtFdu3bljTfeSL4ctWXLluTHtEy0+6tcGaZOhV9+sQ3rR4+GZs3gm2+cjqz40gTggKFDhxIQEJA8CJxkwIABbNq0idDQUObOnUvDhg0LtJ8BAwZgjKFLly5ptp8/f55WrVoxffp0pk6dCmRfQjm9pE5kQUFB9O7dO83ln/x+jtyUqb7++uvZsmVLjuMiWRk/fjxxcXEEBATQtGlTxo8fn/yYlokuPho2tGWnv/7a3u/eHW680a4wVnmUWYlQd/3RctB5M2XKFHnqqafSbKtTp47ExMTk+z0/+OADGTZsWEFDy7fhw4fLkiVLCvU9z507J61atZK4uLhMH9d/Y+7r/HmR114TueQSW3Z6xAiR48edjsr94GbloJWL9ezZkzlz5jBixAinQylU48aN48yZwl08fuDAASZPnpxlO03lvkqVglGjbNnpe+6B11+3Zaf/9z9wg2Urbs/xctB5oeWglRP031jxERVl1+6sXGnHB6ZNs5VHPZ07l4N2nYSLeV89ImJfp5QqdoKCICLCLhz791/o1Al69YK9e52OzD2V3ASQcBHWDYHNo3KfBETs89cN0SSgVDFljO01sHOnXS/w/fd2NfG4cZC4tEUlKrkJwHhB6Uth9/TcJYGkg//u6fZ1puT+aZTyBH5+ttdAdLRdQ/Dii7a+0OzZWnY6Sck9yhkDwVOhwYick0Dqg3+DEfZ16RY3KaWKp8svt70G1q6FK66AwYOhdWt739OV3AQAuUsChXDwf/7552nSpAkBAQEEBQWxfv36QvwQeTNt2rRMZ8lMnDiRJ554Is22qKiofA1uRkVF8Y2uvlHFTNJBf84cOHTILiYbONDe9lQlOwFA9kmgEA7+a9euZfHixWzevJmtW7eydOlSateu7YIPkrOLFy9mmQD69++fvAI4ybx587jjjjvyvJ/8JAB3KCWtlJeX7TUQHW0vD82fDw0a2BaVHll2OrPFAe76U6CFYAkJIptGiMzF/s7sfj4sWLBAbrrppkwfS73oauPGjdK+fXsREZkwYYIMHDhQOnToIFdffbXMmDFDREQiIiKkXbt2cuutt0qjRo3k/vvvl4sXL4qIyMcffyxNmzaVJk2ayOOPP568j3Llysn48eOlZcuWMmnSJPH19ZWmTZtKWFhYhniaN28u69atS75fr149iY6OFhGR77//Xlq3bi3NmzeX2267TU6dOiUiIhs2bJA2bdpIQECAtGjRQv755x+pXbu2+Pv7S2BgoMybN0+OHTsmPXr0kGbNmkmrVq3k559/Tv6c9913n3Tu3Fn69+8v27ZtkxYtWkhgYKA0a9Ysed/uTheClVx794r07i0CInXqiHz6ab4PBW6NLBaCOX5Qz8tPgVcCpz7oJ/0U4OAvInLq1CkJDAyU+vXrywMPPCArVqxIfiy7BBAQECBnzpyRmJgYqVWrlhw+fFgiIiKkdOnS8ttvv0l8fLzccMMN8tlnn8nhw4eldu3acvToUYmLi5MOHTrIF198ISIigISHh2e6z/RefvllGTlypIiIrF27VkJDQ0VEJCYmRtq1ayexsbEiIjJ58mSZNGmSnD9/XurVqycbNmwQEZGTJ09KXFxchtXADz30kEycOFFERJYtWyaBgYHJnzM4OFjOnDmT/LyPPvpIRETOnz+fvN3daQIo+SIiRAIC7BGxXTuRzZudjqhwZZUASv4loNSSLgelVsAB3/LlyxMZGcmMGTOoWrUqffv2ZdasWTm+rkePHvj5+eHv70+HDh2SyzW3bNmSK6+8Em9vb/r378+PP/7Ixo0bCQsLo2rVqvj4+DBgwABWrVoF2GqXvXv3zlWs/fr1Y/78+SQkJDBv3rzkstDr1q1jx44dXHfddQQFBTF79mz279/P7t27qVGjBi1atABs0bbMVsv++OOP3HnnnQB07NiRY8eOJVftTF1Kuk2bNrzwwgu89NJL7N+/X6tvKrcRFgabN9sVxDt3QkgIDB0KR486HZlrOZoAjDGPGmPEGJOxxZMrJF3zTy0v6wSy4O3tTVhYGJMmTeLNN99MbnLi4+NDQuJ8s/RlnbMqqZzZdskmvjJlyuDt7Z2rOGvXrk3dunVZuXIlCxYs4PbbbwfsWWDnzp2JiooiKiqKHTt28N577yEiGeLJTGbxJb0udSnpO+64g0WLFuHn50fXrl1Zvnx5ruJWqih4e8P999uyEiNHwgcf2LISr74KFy44HZ1rOJYAjDG1gc5A0TRiTT/g2z8hd1NEc7B792727NmTfD8qKoo6deoAtjVhZGQkQHJSSLJw4ULOnTvHsWPHWLFiRfK37A0bNvD777+TkJBAeHg4bdu2pVWrVqxcuZK///6bixcv8sknn9C+fftM46lQoUJyI5fMJDWBueqqq5Ib17Ru3Zo1a9Ykl1o+c+YM0dHRNGzYkD/++IONGzcCcOrUKeLj4zPs4/rrr0/ubrZixQr8/f2pWLFihn3v3buXK6+8kuHDh3PLLbewdevWbP6ySjmjUiV47TVbdrptW3j0UWjaFBYvLnltKZ08A5gKPA64/k+a1Wyf3K4TyEZsbCyDBg2icePGBAQEsGPHDiZOnAjAhAkTGDFiBO3atcvwLb1ly5Z0796d1q1bM378eGrWrAnYyyRjx46ladOm1KtXj549e1KjRg1efPFFOnToQGBgIMHBwfTo0SPTeIYOHcqNN95Ihw4dMn28T58+bN++nX79+iVvq1q1KrNmzaJ///4EBATQunVrdu3aRalSpQgPD+fhhx8mMDCQzp07c+7cOTp06MCOHTsICgoiPDyciRMnJpeSHjt2LLNnz8503+Hh4TRt2pSgoCB27drFXXfdldc/t1JFpmFDW3L666/t7KGbb7alpzNp5VF8ZTYw4Oof4BZgeuLtfYB/Ns8dCmwCNl1xxRUZBjdyHKDLabZPIc0GyosJEybIlClTMmyPiIiQ7t27u3z/Km90EFhduCAydarI8OFOR5I/ZDEI7LL6t8aYpUBmzWyfBMYBXTJ5LAMRmQHMAFsNNE9BZPXNP22gKQPDu6fb37oSWCmViq+vHRcoaVyWAETkhsy2G2OaAfWAnxMHCmsBm40xLUXkz0IMIPeLvIo4CSRdIkovLCyMsLAwl+xTKaXSK/IOGCLyC1At6b4xZh8QKiJ/F+A9M85WkQQ4fzz3K3xTJ4Hzx+3rTe5m16iSS0raqJ9SqRT7FkhlypTh2LFjVKlSJW0S8PKG1h/Yqp65/SaflAQkwb5eeTQR4dixY5QpU8bpUJRyCccTgIjULcjra9WqxaFDh4iJiSmkiJRKUaZMmeTpskqVNI4ngILy9fWlXr16ToehlFLFjmeVglBKKZVME4BSSnkoTQBKKeWhTHGa5maMiQH25/Pl/kC+p5oWU/qZPYN+Zs9QkM9cR0Sqpt9YrBJAQRhjNolIqNNxFCX9zJ5BP7NncMVn1ktASinloTQBKKWUh/KkBDDD6QAcoJ/ZM+hn9gyF/pk9ZgxAKaVUWp50BqCUUioVTQBKKeWhPCIBGGO6GWN2G2N+NcaMdToeVzPG1DbGRBhjdhpjthtjRjgdU1EwxngbY7YYYxY7HUtRMMZUMsbMN8bsSvxv3cbpmFzNGDMq8d/0NmPMJ8aYEleq1RjzvjHmqDFmW6ptlxpjlhhj9iT+rlwY+yrxCcAY4w28BdwINAb6G2MaOxuVy8UDo0WkEdAaGOYBnxlgBLDT6SCK0HTgOxFpCARSwj+7MeZyYDi2f0hTwBvol/2riqVZQLd028YCy0SkPrAs8X6BlfgEALQEfhWRvSJyAZgHZN5RvYQQkSMisjnx9insgeFyZ6NyLWNMLaA7MNPpWIqCMaYicD3wHoCIXBCRf5yNqkj4AH7GGB+gLPCHw/EUOhFZBRxPt7kHMDvx9mzg1sLYlyckgMuBg6nuH6KEHwxTM8bUBZoD652NxOWmAY8DCU4HUkSuBGKADxIve800xpRzOihXEpHDwCvAAeAIcFJEfnA2qiJTXUSOgP2CR6quigXhCQkgs3ZgHjH31RhTHlgAjBSRf52Ox1WMMTcBR0Uk0ulYipAPEAy8LSLNgdMU0mUBd5V43bsHtqd4TaCcMWags1EVb56QAA4BtVPdr0UJPG1Mzxjjiz34zxWRz52Ox8WuA25J7C89D+hojPnI2ZBc7hBwSESSzuzmYxNCSXYD8LuIxIhIHPA5cK3DMRWVv4wxNQASfx8tjDf1hASwEahvjKlnjCmFHTRa5HBMLmVsc+T3gJ0i8prT8biaiDwhIrUS24v2A5aLSIn+ZigifwIHjTENEjd1AnY4GFJROAC0NsaUTfw33okSPvCdyiJgUOLtQcDCwnjTYt8SMiciEm+MeQj4Hjtr4H0R2e5wWK52HXAn8IsxJipx2zgR+cbBmFThexiYm/jFZi8wxOF4XEpE1htj5gObsTPdtlACS0IYYz4BwgB/Y8whYAIwGfjUGHMPNhH2KZR9aSkIpZTyTJ5wCUgppVQmNAEopZSH0gSglFIeShOAUkp5KE0ASinloTQBKJUHiZVWfzfGXJp4v3Li/TrGmO+MMf94SjVSVfxpAlAqD0TkIPA2dl42ib9niMh+YAp2/YVSxYImAKXybip2RepIoC3wKoCILANOORmYUnlR4lcCK1XYRCTOGPMY8B3QJbHMuFLFjp4BKJU/N2JLEjd1OhCl8ksTgFJ5ZIwJAjpju62NSqrSqFRxowlAqTxIrEL5NrbHwgHswO8rzkalVP5oAlAqb+4DDojIksT7/wc0NMa0N8asBj4DOhljDhljujoWpVK5oNVAlVLKQ+kZgFJKeShNAEop5aE0ASillIfSBKCUUh5KE4BSSnkoTQBKKeWhNAEopZSH+n+GZaw6nw5fBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(x1,x2, c=colors)\n",
    "plt.plot(SVMline_X,SVMline_Y, color = \"magenta\", label = \"SVM hyperplane (line)\")\n",
    "plt.plot(x_l,y_l, color = \"blue\", label = \"Initial hyperplane (line)\")\n",
    "plt.scatter(support_vectors.transpose()[0],support_vectors.transpose()[1], color=\"orange\", marker = \"x\", s = 200, label = \"Support Vectors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have developed the SVM for this problem, we can test our classifier on new data. Based on the visual above, we know that a datapoint at (2,2) will be classified as 0 (green) and point (10,10) will be classified as 1 (red) based on the hyperplane that seperates our data. To test this, we can use the predict function from the Scikit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array( [[2,2] , [10,10]])\n",
    "y_pred = svmModel.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the output above, our SVM model predicted the data correctly. An alternative way to test the SVM model, especially when testing on large datasets, is to use the score function. This score function compares the predicted output to the real output to calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = [0, 1] #True labels associated with X_test\n",
    "accuracy = svmModel.score(X_test,y_true)\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above output, we can see that our SVM classified our test data correctly with 100% accuracy!\n",
    "\n",
    "Next, we will look at a more complex application of SVM using non-linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SVM for Cyber Threat Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration of non-linear SVM, we will consider the application of attack detection in power systems. Since we are done with the previous example, I will clear the defined variables to avoid confusion and errors and re-import the libaries we've been using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, here's a quick background to this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's power systems consist of networked architecture to allow for more efficient power generation and use of multiple (potentially green) sources of energy. This networked architecture, however, is vulnerable to cyber attacks. Many cyber attacks today are designed in a stealthy manner that is capable of bypassing the \"bad data detection\" methods employed in most power system. This is because the current methods involve mathematical modelling of measurements through state estimation. Therefore, many researchers propose security methods that involve machine learning and intelligent algorithms. In this tutorial, we will explore the ability of SVM to detect the presence of a cyber attack by using various measurements of the power system as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this tutorial is generated by Oak Ridge National Laboratories (ORNL) [5]. We will be using the first power system dataset shared on their website. For convenience, I have uploaded this dataset into my github repository so we can load it in this notebook without external dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataURL = 'https://raw.githubusercontent.com/jsakhnin-ai/IEEE_DATA/master/ICSdata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the pandas library, which is a great tool for reading/writing data, to the read the csv file directly from the above URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Used to read files\n",
    "data = pd.read_csv(dataURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is in a dataframe object. We can use the \"head\" function associated with the dataframe object to see the first 5 rows (not including the headers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-PA1:VH</th>\n",
       "      <th>R1-PM1:V</th>\n",
       "      <th>R1-PA2:VH</th>\n",
       "      <th>R1-PM2:V</th>\n",
       "      <th>R1-PA3:VH</th>\n",
       "      <th>R1-PM3:V</th>\n",
       "      <th>R1-PA4:IH</th>\n",
       "      <th>R1-PM4:I</th>\n",
       "      <th>R1-PA5:IH</th>\n",
       "      <th>R1-PM5:I</th>\n",
       "      <th>...</th>\n",
       "      <th>control_panel_log4</th>\n",
       "      <th>relay1_log</th>\n",
       "      <th>relay2_log</th>\n",
       "      <th>relay3_log</th>\n",
       "      <th>relay4_log</th>\n",
       "      <th>snort_log1</th>\n",
       "      <th>snort_log2</th>\n",
       "      <th>snort_log3</th>\n",
       "      <th>snort_log4</th>\n",
       "      <th>marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>70.399324</td>\n",
       "      <td>127673.0908</td>\n",
       "      <td>-49.572308</td>\n",
       "      <td>127648.0176</td>\n",
       "      <td>-169.578319</td>\n",
       "      <td>127723.2374</td>\n",
       "      <td>65.689611</td>\n",
       "      <td>605.91099</td>\n",
       "      <td>-57.003571</td>\n",
       "      <td>626.78553</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>73.688102</td>\n",
       "      <td>130280.7109</td>\n",
       "      <td>-46.300719</td>\n",
       "      <td>130255.6377</td>\n",
       "      <td>-166.278082</td>\n",
       "      <td>130355.9307</td>\n",
       "      <td>71.831719</td>\n",
       "      <td>483.59351</td>\n",
       "      <td>-50.947407</td>\n",
       "      <td>500.98896</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>73.733939</td>\n",
       "      <td>130305.7842</td>\n",
       "      <td>-46.254883</td>\n",
       "      <td>130280.7109</td>\n",
       "      <td>-166.232245</td>\n",
       "      <td>130381.0040</td>\n",
       "      <td>71.808800</td>\n",
       "      <td>483.59351</td>\n",
       "      <td>-50.913030</td>\n",
       "      <td>500.98896</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>74.083443</td>\n",
       "      <td>130581.5902</td>\n",
       "      <td>-45.899649</td>\n",
       "      <td>130556.5169</td>\n",
       "      <td>-165.882741</td>\n",
       "      <td>130656.8100</td>\n",
       "      <td>72.152575</td>\n",
       "      <td>482.86107</td>\n",
       "      <td>-50.437475</td>\n",
       "      <td>499.15786</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>74.553268</td>\n",
       "      <td>131083.0556</td>\n",
       "      <td>-45.424094</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>-165.424375</td>\n",
       "      <td>131158.2754</td>\n",
       "      <td>72.118198</td>\n",
       "      <td>484.50906</td>\n",
       "      <td>-50.013486</td>\n",
       "      <td>497.69298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R1-PA1:VH     R1-PM1:V  R1-PA2:VH     R1-PM2:V   R1-PA3:VH     R1-PM3:V  \\\n",
       "0  70.399324  127673.0908 -49.572308  127648.0176 -169.578319  127723.2374   \n",
       "1  73.688102  130280.7109 -46.300719  130255.6377 -166.278082  130355.9307   \n",
       "2  73.733939  130305.7842 -46.254883  130280.7109 -166.232245  130381.0040   \n",
       "3  74.083443  130581.5902 -45.899649  130556.5169 -165.882741  130656.8100   \n",
       "4  74.553268  131083.0556 -45.424094  131057.9823 -165.424375  131158.2754   \n",
       "\n",
       "   R1-PA4:IH   R1-PM4:I  R1-PA5:IH   R1-PM5:I  ...  control_panel_log4  \\\n",
       "0  65.689611  605.91099 -57.003571  626.78553  ...                   0   \n",
       "1  71.831719  483.59351 -50.947407  500.98896  ...                   0   \n",
       "2  71.808800  483.59351 -50.913030  500.98896  ...                   0   \n",
       "3  72.152575  482.86107 -50.437475  499.15786  ...                   0   \n",
       "4  72.118198  484.50906 -50.013486  497.69298  ...                   0   \n",
       "\n",
       "   relay1_log  relay2_log  relay3_log  relay4_log  snort_log1  snort_log2  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   snort_log3  snort_log4   marker  \n",
       "0           0           0  Natural  \n",
       "1           0           0  Natural  \n",
       "2           0           0  Natural  \n",
       "3           0           0  Natural  \n",
       "4           0           0  Natural  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data contains 129 features (measurements) which are each labelled with a header indicating each measurement. We can also use the \"tail\" function to see the last 5 rows of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-PA1:VH</th>\n",
       "      <th>R1-PM1:V</th>\n",
       "      <th>R1-PA2:VH</th>\n",
       "      <th>R1-PM2:V</th>\n",
       "      <th>R1-PA3:VH</th>\n",
       "      <th>R1-PM3:V</th>\n",
       "      <th>R1-PA4:IH</th>\n",
       "      <th>R1-PM4:I</th>\n",
       "      <th>R1-PA5:IH</th>\n",
       "      <th>R1-PM5:I</th>\n",
       "      <th>...</th>\n",
       "      <th>control_panel_log4</th>\n",
       "      <th>relay1_log</th>\n",
       "      <th>relay2_log</th>\n",
       "      <th>relay3_log</th>\n",
       "      <th>relay4_log</th>\n",
       "      <th>snort_log1</th>\n",
       "      <th>snort_log2</th>\n",
       "      <th>snort_log3</th>\n",
       "      <th>snort_log4</th>\n",
       "      <th>marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4961</td>\n",
       "      <td>28.229631</td>\n",
       "      <td>130882.4694</td>\n",
       "      <td>-91.730543</td>\n",
       "      <td>130882.4694</td>\n",
       "      <td>148.264289</td>\n",
       "      <td>130957.6892</td>\n",
       "      <td>25.553918</td>\n",
       "      <td>459.42299</td>\n",
       "      <td>-95.683952</td>\n",
       "      <td>466.93050</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4962</td>\n",
       "      <td>28.195253</td>\n",
       "      <td>130957.6892</td>\n",
       "      <td>-91.770650</td>\n",
       "      <td>130932.6159</td>\n",
       "      <td>148.224182</td>\n",
       "      <td>131032.9090</td>\n",
       "      <td>25.267439</td>\n",
       "      <td>460.70476</td>\n",
       "      <td>-95.752707</td>\n",
       "      <td>467.66294</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4963</td>\n",
       "      <td>28.000447</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>-91.971185</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>148.035105</td>\n",
       "      <td>131133.2021</td>\n",
       "      <td>24.316329</td>\n",
       "      <td>464.36696</td>\n",
       "      <td>-96.251180</td>\n",
       "      <td>468.94471</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4964</td>\n",
       "      <td>27.971800</td>\n",
       "      <td>131083.0556</td>\n",
       "      <td>-91.994104</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>148.006458</td>\n",
       "      <td>131133.2021</td>\n",
       "      <td>24.259033</td>\n",
       "      <td>464.18385</td>\n",
       "      <td>-96.314205</td>\n",
       "      <td>469.12782</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4965</td>\n",
       "      <td>27.931693</td>\n",
       "      <td>131083.0556</td>\n",
       "      <td>-92.034211</td>\n",
       "      <td>131057.9823</td>\n",
       "      <td>147.966351</td>\n",
       "      <td>131133.2021</td>\n",
       "      <td>24.241844</td>\n",
       "      <td>464.00074</td>\n",
       "      <td>-96.342853</td>\n",
       "      <td>469.12782</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      R1-PA1:VH     R1-PM1:V  R1-PA2:VH     R1-PM2:V   R1-PA3:VH     R1-PM3:V  \\\n",
       "4961  28.229631  130882.4694 -91.730543  130882.4694  148.264289  130957.6892   \n",
       "4962  28.195253  130957.6892 -91.770650  130932.6159  148.224182  131032.9090   \n",
       "4963  28.000447  131057.9823 -91.971185  131057.9823  148.035105  131133.2021   \n",
       "4964  27.971800  131083.0556 -91.994104  131057.9823  148.006458  131133.2021   \n",
       "4965  27.931693  131083.0556 -92.034211  131057.9823  147.966351  131133.2021   \n",
       "\n",
       "      R1-PA4:IH   R1-PM4:I  R1-PA5:IH   R1-PM5:I  ...  control_panel_log4  \\\n",
       "4961  25.553918  459.42299 -95.683952  466.93050  ...                   0   \n",
       "4962  25.267439  460.70476 -95.752707  467.66294  ...                   0   \n",
       "4963  24.316329  464.36696 -96.251180  468.94471  ...                   0   \n",
       "4964  24.259033  464.18385 -96.314205  469.12782  ...                   0   \n",
       "4965  24.241844  464.00074 -96.342853  469.12782  ...                   0   \n",
       "\n",
       "      relay1_log  relay2_log  relay3_log  relay4_log  snort_log1  snort_log2  \\\n",
       "4961           0           0           0           0           0           0   \n",
       "4962           0           0           0           0           0           0   \n",
       "4963           0           0           0           0           0           0   \n",
       "4964           0           0           0           0           0           0   \n",
       "4965           0           0           0           0           0           0   \n",
       "\n",
       "      snort_log3  snort_log4   marker  \n",
       "4961           0           0  Natural  \n",
       "4962           0           0  Natural  \n",
       "4963           0           0  Natural  \n",
       "4964           0           0  Natural  \n",
       "4965           0           0  Natural  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the last column of our data, labeled \"marker\", is our label, we will assin it to a different variable, and drop that column from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['marker']\n",
    "data = data.drop('marker', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing of data is necessary prior to using machine learning algorithm. It is important to consider errors in the measurement or unknown values. A good example of this is having infinity values in the data. To do this check, we will use the numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 738,  739,  753,  777,  778,  779,  780,  798,  799,  800,  812,\n",
       "         834,  835,  847,  864,  865,  866,  887,  888,  901,  916,  928,\n",
       "         939,  940,  971,  972, 1038, 1073, 1074, 1075, 1093, 1094, 1119,\n",
       "        1120, 1121, 1151, 1152, 1153, 1349, 1350, 1351, 1352, 1384, 1385,\n",
       "        1417, 1418, 1445, 1498, 1499, 1500, 1527, 1528, 1557, 1558, 1583,\n",
       "        1584, 1608, 1609, 1666, 1667, 1697, 1698, 1721, 1751, 1752, 1753,\n",
       "        1754, 1794, 1795, 1832, 1833, 1833, 1833, 1833, 1863, 1863, 1863,\n",
       "        1863, 1864, 1864, 1864, 1864, 1865, 1866, 1901, 1901, 1901, 1901,\n",
       "        1902, 1902, 1902, 1902, 1903, 1903, 1903, 1903, 1933, 1933, 1933,\n",
       "        1933, 1934, 1934, 1934, 1934, 1964, 1964, 1964, 1964, 1965, 1965,\n",
       "        1965, 1965, 2001, 2001, 2001, 2001, 2002, 2002, 2002, 2002, 2003,\n",
       "        2003, 2003, 2003, 2031, 2031, 2031, 2031, 2032, 2032, 2032, 2032,\n",
       "        2033, 2033, 2033, 2033, 2034, 2034, 2034, 2034, 2070, 2070, 2070,\n",
       "        2070, 2109, 2109, 2109, 2109, 2142, 2142, 2142, 2142, 2143, 2143,\n",
       "        2143, 2143, 2144, 2144, 2144, 2144, 2145, 2145, 2145, 2145, 2146,\n",
       "        2146, 2146, 2146, 2147, 2147, 2147, 2147, 2148, 2148, 2148, 2148,\n",
       "        2191, 2191, 2191, 2191, 2192, 2192, 2192, 2192, 2193, 2193, 2193,\n",
       "        2193, 2194, 2194, 2194, 2194, 2195, 2195, 2195, 2195, 2230, 2230,\n",
       "        2230, 2230, 2277, 2277, 2277, 2277, 2300, 2300, 2300, 2300, 2301,\n",
       "        2301, 2301, 2301, 2302, 2302, 2302, 2302, 2303, 2303, 2303, 2303,\n",
       "        2304, 2304, 2304, 2304, 2305, 2305, 2305, 2305, 2331, 2331, 2331,\n",
       "        2331, 2364, 2364, 2364, 2364, 2365, 2365, 2365, 2365, 2366, 2366,\n",
       "        2366, 2366, 2393, 2393, 2393, 2393, 2394, 2394, 2394, 2394, 2395,\n",
       "        2395, 2395, 2395, 2424, 2424, 2424, 2424, 2425, 2425, 2425, 2425,\n",
       "        2426, 2426, 2426, 2426, 2453, 2453, 2453, 2453, 2454, 2454, 2454,\n",
       "        2454, 2484, 2484, 2484, 2484, 2485, 2485, 2485, 2485, 2516, 2516,\n",
       "        2516, 2516, 2517, 2517, 2517, 2517, 2518, 2518, 2518, 2518, 2519,\n",
       "        2519, 2519, 2519, 2548, 2548, 2548, 2548, 2580, 2581, 2615, 2615,\n",
       "        2615, 2615, 2705, 2706, 2707, 2739, 2740, 2741, 2780, 2823, 2839,\n",
       "        2840, 2841, 2870, 2889, 2897, 2915, 2916, 2942, 2943, 2958, 2959,\n",
       "        2978, 2990, 2991, 2992, 3021, 3021, 3022, 3022, 3023, 3023, 3051,\n",
       "        3051, 3075, 3075, 3111, 3111, 3112, 3112, 3113, 3113, 3114, 3114,\n",
       "        3131, 3148, 3149, 3165, 3166, 3167, 3168, 3191, 3192, 3193, 3194,\n",
       "        3195, 3211, 3212, 3213, 3214, 3227, 3243, 3244, 3245, 3267, 3310,\n",
       "        3311, 3312, 3313, 3314, 3342, 3363, 3364, 3389, 3390, 3417, 3436,\n",
       "        3456, 3475, 3475, 3476, 3476, 3499, 3499, 3517, 3517, 3518, 3518,\n",
       "        3532, 3532, 3533, 3533, 3534, 3534, 3560, 3560, 3586, 3586, 3587,\n",
       "        3587, 3588, 3588, 3607, 3607, 3608, 3608, 3609, 3609, 3656, 3656,\n",
       "        3657, 3657, 3679, 3679, 3680, 3680, 3681, 3681, 3682, 3682, 3683,\n",
       "        3683, 3684, 3684, 3700, 3700, 3701, 3701, 3702, 3702, 3739, 3739,\n",
       "        3740, 3740, 3741, 3741, 3742, 3742, 3743, 3743, 3776, 3776, 3777,\n",
       "        3777, 3811, 3811, 3812, 3812, 3813, 3813, 3842, 3842, 3843, 3843,\n",
       "        3844, 3844, 3922, 3922, 3950, 3950, 3951, 3951, 3952, 3952, 3953,\n",
       "        3953, 3987, 3987, 3988, 3988, 3989, 3989, 4017, 4017, 4033, 4033,\n",
       "        4034, 4034, 4035, 4035, 4036, 4036, 4054, 4054, 4055, 4055, 4056,\n",
       "        4056, 4078, 4078, 4093, 4093, 4094, 4094, 4095, 4095, 4128, 4128,\n",
       "        4129, 4129, 4147, 4147, 4148, 4148, 4149, 4149, 4150, 4150, 4151,\n",
       "        4151, 4173, 4173, 4174, 4174, 4210, 4210, 4211, 4211, 4212, 4212,\n",
       "        4228, 4228, 4246, 4267, 4267, 4268, 4268, 4269, 4269, 4270, 4270,\n",
       "        4271, 4271, 4272, 4272, 4273, 4273, 4293, 4293, 4294, 4294, 4310,\n",
       "        4374, 4375, 4375, 4376, 4377, 4460, 4460, 4461, 4461, 4489, 4489,\n",
       "        4537, 4538, 4538, 4539, 4539, 4540, 4540, 4541, 4541, 4542, 4558,\n",
       "        4558, 4559, 4559, 4586, 4587, 4587, 4588, 4588, 4589, 4589, 4637,\n",
       "        4637, 4638, 4638, 4639, 4639, 4640, 4672, 4672, 4673, 4673, 4697,\n",
       "        4698, 4698, 4699, 4699, 4700, 4700, 4701, 4722, 4722, 4723, 4723,\n",
       "        4741, 4741, 4742, 4758, 4759, 4759, 4775, 4776, 4776, 4777, 4777,\n",
       "        4793, 4793, 4794, 4794, 4795, 4795, 4815, 4815, 4830, 4831, 4831,\n",
       "        4845, 4846, 4846, 4847, 4847, 4848, 4848, 4867, 4867, 4868, 4868,\n",
       "        4884, 4884, 4885, 4885, 4886, 4886, 4887, 4887, 4888, 4888, 4906,\n",
       "        4906, 4921, 4921, 4922, 4922, 4939, 4939, 4951, 4951, 4952, 4952,\n",
       "        4953, 4953, 4954, 4954, 4955], dtype=int64),\n",
       " array([ 26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,\n",
       "         26,  26,  26,  26,  26,  26,  26,  26,  26, 113, 113, 113, 113,\n",
       "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,  84,\n",
       "         84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,\n",
       "         84,  84,  84,  84,  84,  84,  84,  84,  84,  84, 113, 113, 113,\n",
       "        113, 113, 113, 113, 113,  26,  55,  84, 113,  26,  55,  84, 113,\n",
       "         26,  55,  84, 113,  26,  26,  26,  55,  84, 113,  26,  55,  84,\n",
       "        113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,\n",
       "         26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,\n",
       "         55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,\n",
       "         84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84,\n",
       "        113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,\n",
       "         26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,\n",
       "         55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,\n",
       "         84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84,\n",
       "        113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,\n",
       "         26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,\n",
       "         55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,\n",
       "         84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84,\n",
       "        113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,\n",
       "         26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,\n",
       "         55,  84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,\n",
       "         84, 113,  26,  55,  84, 113,  26,  55,  84, 113,  26,  55,  84,\n",
       "        113,  26,  55,  84, 113,  26,  26,  26,  55,  84, 113,  26,  26,\n",
       "         26,  26,  26,  26,  26,  55,  55,  55,  55,  55,  55,  55,  55,\n",
       "         55,  55,  55,  55,  55,  55,  55,  55,  55,  84, 113,  84, 113,\n",
       "         84, 113,  84, 113,  26,  55,  26,  55,  26,  55,  26,  55,  26,\n",
       "         55, 113, 113, 113, 113, 113, 113, 113,  84,  84,  84,  84,  84,\n",
       "         84,  84,  84,  84,  84,  55,  55,  55,  55,  26,  26,  26,  26,\n",
       "         26,  26,  26,  26,  26,  26,  26,  26,  26,  84, 113,  84, 113,\n",
       "         84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84,\n",
       "        113,  84, 113,  84, 113,  84, 113,  26,  55,  26,  55,  26,  55,\n",
       "         26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,\n",
       "         55,  26,  55,  26,  55,  26,  55,  26,  55,  84, 113,  84, 113,\n",
       "         84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84,\n",
       "        113,  84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84, 113,\n",
       "         84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84, 113,  84,\n",
       "        113,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,\n",
       "         26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,\n",
       "         55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,\n",
       "         26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  26,  55,\n",
       "         26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,\n",
       "         55,  26,  55, 113, 113,  84, 113,  84,  84,  84, 113,  84, 113,\n",
       "         84, 113,  84,  84, 113,  84, 113,  84, 113,  84, 113, 113,  84,\n",
       "        113,  84, 113,  84,  84, 113,  84, 113,  84, 113,  84, 113,  84,\n",
       "        113,  84, 113, 113,  84, 113,  84, 113,  55,  26,  55,  26,  55,\n",
       "         26,  55,  26,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,\n",
       "         55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,\n",
       "         55,  26,  55,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,\n",
       "         55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,\n",
       "         26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,  55,  26,\n",
       "         55,  55], dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import inf\n",
    "np.where(data==inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output tells us the location in the dataset where the value is inifnity. The first array corresponds to rows and the second correspond to columns. For example, the first infinity value is in row 738 and column 26:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_numpy()[738][26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the infinity values are likely from recording or computational errors, we will replace these values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(-inf, 0)\n",
    "data = data.replace(inf, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we removed problematic infinite values from our data, the next step is to remove zero columns or useless features from our dataset. This data, in fact, contains several zero columns corresponding to log data that was not recorded. An example of this is the control panel log data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  0.0\n",
      "Standard deviation =  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"mean = \", data['control_panel_log1'].mean() )\n",
    "print(\"Standard deviation = \", data['control_panel_log1'].std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mean and standard deviation of zero tells us that the \"control_panel_log1\" column is all zeros. Performing a similar check on every column (potentially through a loop) yields in 12 zero columns. Let's remove these zero columns from our data to increase the computational efficiency and performance of the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['snort_log1','snort_log2','snort_log3','snort_log4',\n",
    "                'control_panel_log1','control_panel_log2','control_panel_log3','control_panel_log4',\n",
    "                'relay1_log','relay2_log','relay3_log','relay4_log'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we note that the labels are identified by a string containing \"Attack\" or \"Natural\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Natural', 'Attack'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert these labels to binary values for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.replace('Attack', 1)\n",
    "labels = labels.replace('Natural', 0)\n",
    "labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is clean, the last thing to do is to scale the data. Scaling the data is essentially changing the range of the data without affecting the distribution of the data. This is critical for algorithms, like the SVM, which function based on differences among data points. Scaling is helpful in increasing the computational efficiency of machine learning algorithms. To scale our data, we will use preprocessing library from Scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scalar = preprocessing.StandardScaler()\n",
    "data = scalar.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready to begin training our SVM! But first, we will convert our data to numpy arrays for easy processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(data)\n",
    "y =  np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data and labels are in the correct format, we are ready to start implementing the SVM classifier. But before we begin to train our SVM, we must consider a method in which we can test it. Since we need to know how well our SVM performs on unseen data, it is important to divide the data we have into training and testing data. Luckily, Scikit learn makes this very easy using one simple function called \"test_train_split\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code split our data into training and testing data in a 7-3 split where the training data and testing data account for 70% and 30% of the data respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (3476, 116)\n",
      "Size of training labels:  (3476,)\n",
      "Size of testing data:  (1490, 116)\n",
      "Size of testing labels:  (1490,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data: \" , X_train.shape)\n",
    "print(\"Size of training labels: \" , y_train.shape)\n",
    "print(\"Size of testing data: \" , X_test.shape)\n",
    "print(\"Size of testing labels: \" , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of this \"test_train_split\" function is that it automatically shuffels our data so we have an even distribution in both training and testing data. This is very important because the data we have is sorted by class (label). We can confirm this by plotting either the training or testing labels. It is important to make sure that the training and testing data contain samples associate with all the labels we are trying to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19e2af1ae10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(y_test.shape[0]), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Attack Detection using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to section 2.1, we begin by creating a classifier object. Let's start by trying the exact same model as section 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmModel = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train this SVM model on our training data, then test it on the testing data, similarly to what was done in section 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmModel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is trained on the training data, we can test its accuracy on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7885906040268457\n"
     ]
    }
   ],
   "source": [
    "accuracy = svmModel.score(X_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an accuracy of 78%! *(value may vary slightly with every run)* But up until now, we have been using the default parameter. As discussed in section 1, the regularization parameter, $C$, affects the tolerance of miss-classification. For larger values of C, the algorithm will choose a smaller-margin hyperplane if that hyperplane better classifies the data. This means that increasing the C value might increase the accuracy of our model. But how much do we increase it by? What is an ideal value of C? Such questions are typically answered with experimental testing. One thing we can do is create a loop in which the SVM is trained with different C values. The default C value is 1, let's try testing other values of C. We will also track the time it takes to train for each value of C because computational efficiency is important.\n",
    "\n",
    "**Warning: The below code might take up to few minutes to execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 0.1, Accuracy = 0.7899328859060403, Training Time = 0.9470846652984619 seconds\n",
      "C value = 10, Accuracy = 0.7865771812080536, Training Time = 5.237265348434448 seconds\n",
      "C value = 100, Accuracy = 0.7953020134228188, Training Time = 39.285279512405396 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "cValues = [0.1,10,100]\n",
    "\n",
    "for c in cValues:\n",
    "    svmModel = svm.SVC(kernel = 'linear', C=c)\n",
    "    time1 = time.time()\n",
    "    svmModel.fit(X_train,y_train)\n",
    "    time2 = time.time()\n",
    "    print( \"C value = {}, Accuracy = {}, Training Time = {} seconds\".format( c, svmModel.score(X_test,y_test), time2-time1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results above, changing our $C$ value had very little effect on the accuracy, in fact, higher $C$ values significantly increased the training time thereby reducing the computational efficiency of our classifier. So how can we further increase the accuracy of our model?\n",
    "Recall that up until now, we used a linear kernel in the SVM. As explained in section 1, kernels are a useful tool that can help the SVM seperate the data in a non-linear fashion. A very popular and common kernel is the Radial Basis Function (RBF) kernel. The RBF kernel on two samples, $x$ and $x^{\\prime}$, are represented as feature vectors in some input space defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "K\\left(\\mathbf{x}, \\mathbf{x}^{\\prime}\\right)=\\exp \\left(-\\frac{\\left\\|\\mathbf{x}-\\mathbf{x}^{\\prime}\\right\\|^{2}}{2 \\sigma^{2}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\left\\|\\mathbf{x}-\\mathbf{x}^{\\prime}\\right\\|^{2}$ is the squared euclidean distance, and $\\sigma$ is a parameter. An alternative way of writing this, which is more relevant to the Scikit learn implementation, is as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "K\\left(\\mathbf{x}, \\mathbf{x}^{\\prime}\\right)=\\exp \\left(-\\gamma\\left\\|\\mathbf{x}-\\mathbf{x}^{\\prime}\\right\\|^{2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\gamma=\\frac{1}{2 \\sigma^{2}}$ is known as the kernel parameter ('gamma' in sklearn).\n",
    "\n",
    "So let's try using the RBF kernel! For now, we will  arbitrarily choose $C = 1$ and $\\gamma = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536912751677852\n"
     ]
    }
   ],
   "source": [
    "svmModel = svm.SVC(kernel = 'rbf', C=1, gamma = 0.1)\n",
    "svmModel.fit(X_train,y_train)\n",
    "accuracy = svmModel.score(X_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our accuracy improved when using the RBF kernel. This is likely due to the fact that our data is not linearly seperable. Using a kernel allows the SVM to analyze our data in a different space and thus is capable of finding a hyperplane that better seperates our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Cross-Validation and Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to consider is the modification of the $C$ and $\\gamma$ parameters. We can, once again, run a loop in which the SVM is tested under various parameters but this can be very time consuming. Luckily, there are algorithms such as the *Grid Search* algorithm which is used to search for the ideal parameters of machine learning algorithms. The grid search algorithm divides the data into a number of subsets, each of the subsets is divided into training and validation, then trains the machine learning algorithm on the training part of the subset and tests it on the validation part. The performance of the algorithm in each of the subsets is averaged and the results for each set of parameters are compared.\n",
    "In python, this can be easily implemented using the Scikit learn library.\n",
    "\n",
    "To implement the grid search algorithm, we can use GridSearchCV object from sklearn library which takes the classfier object (our SVM model), a grid of parameters, a scoring methods, and the number of subsets to divide the data into. In the below code, we will implement the grid search using 5 folds to test for three different $C$ values and three different $\\gamma\\$ values; in other words, a grid of 3x3 = 9 different SVM models.\n",
    "\n",
    "**Warning: The below code might take (up to) a few minutes to execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=svm.SVC(kernel = 'rbf'),\n",
    "                     param_grid=parameter_grid,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5)\n",
    "\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our grid search is complete, we can view the resultant best parameters and the resultant score (accuracy) associated with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n",
      "0.9159953970080552\n"
     ]
    }
   ],
   "source": [
    "best_parameters = gs.best_params_\n",
    "best_score = gs.best_score_\n",
    "print(best_parameters)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we achived an accuracy of 92%! *(value may vary slightly with every run)* This is a significant improvement over the accuracies we attained with previous models. For further testing, we can train an SVM model with these parameters on all of the $X_{train}$ data and then test it on our testing data, $X_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the SVM model =  0.9281879194630872\n"
     ]
    }
   ],
   "source": [
    "svmModel = svm.SVC(kernel = 'rbf', C=10, gamma = 1)\n",
    "svmModel.fit(X_train,y_train)\n",
    "accuracy = svmModel.score(X_test,y_test)\n",
    "print(\"The accuracy of the SVM model = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We began with 77% accuracy and now we have a model that is 93% accurate! *(values may vary slightly with every run)* This demonstrates the importance of parameter tuning and its effect on the performance of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we established the fundemental theory of Support Vector Machines (SVM), we demonstrated this theory through a basic linear example, then explored a more sophisticated application of SVM involving cyber-attack detection in power systems. We then concluded that Support Vector Machines, much like most classification algorithms, are optimized through cross-validation of varying hyper-parameters. This was demonstrated by modifying the regularization parameter, $C$, and the kernel coefficient, $\\gamma$, such that the classification accuracy on unseen data is maximized. The final results show that SVM was successful in this application. It is also worth noting that while most developers tend to diverge towards deep learning techniques for solving such problems, in some cases a simple classifier such as the SVM can be just as successful and even more benefitial than deep neural networks. In certain cases, some classifiers can achieve similar performance with less time than deep neural networks. Therefore, it is crucial for any machine learning developer to be fimiliar with the various classification methods, as well as their benefits and drawbacks, to solve problems in the most efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] S. Sayad, “Support Vector Machine.” [Online]. Available: https://www.saedsayad.com/support_vector_machine.htm. [Accessed: 02-Nov-2019].\n",
    "\n",
    "[2] M. P. Deisenroth, A. A. Faisal, and C. S. Ong, “Mathematics for Machine Learning,” p. 417.\n",
    "\n",
    "[3] Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, Édouard Duchesnay. Scikit-learn: Machine Learning in Python, Journal of Machine Learning Research, 12, 2825-2830 (2011) \n",
    "\n",
    "[4] S. van der Walt, S. Chris Colbert and G. Varoquaux. The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science & Engineering, 13, 22-30 (2011)\n",
    "\n",
    "[5] Beaver, Justin M., Borges-Hink, Raymond C., Buckner, Mark A., \"An Evaluation of Machine Learning Methods to Detect Malicious SCADA Communications,\" in the Proceedings of 2013 12th International Conference on Machine Learning and Applications (ICMLA), vol.2, pp.54-59, 2013."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
